{"id":"opencode-swarm-monorepo-lf2p4u-mjepneb3e6h","title":"Fix remaining 9 test failures","description":"Three distinct issue groups:\n\n1. **swarm_decompose/plan_prompt** (3 failures) - Prompt content assertions failing. Tests expect certain content in generated prompts that isn't there.\n\n2. **Checkpoint/Recovery** (3 failures) - \"there is no unique or exclusion constraint matching the ON CONFLICT specification\" - The swarm_contexts table is missing a unique constraint needed for UPSERT operations.\n\n3. **FTS search** (1 failure) - Full-text search fallback test failing. Likely missing FTS5 virtual table or triggers in test setup.","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-12-20T19:48:02.991Z","updated_at":"2025-12-20T20:02:34.360Z","closed_at":"2025-12-20T20:02:34.360Z","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjepneb7ybq","title":"Fix swarm_decompose and swarm_plan_prompt tests","status":"closed","priority":0,"issue_type":"task","created_at":"2025-12-20T19:48:02.995Z","updated_at":"2025-12-20T20:02:27.546Z","closed_at":"2025-12-20T20:02:27.546Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjepneb3e6h","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjepneba91m","title":"Fix checkpoint/recovery - add unique constraint to swarm_contexts","status":"closed","priority":0,"issue_type":"task","created_at":"2025-12-20T19:48:02.998Z","updated_at":"2025-12-20T20:02:29.114Z","closed_at":"2025-12-20T20:02:29.114Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjepneb3e6h","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjepnebcihu","title":"Fix FTS search fallback test","status":"closed","priority":0,"issue_type":"task","created_at":"2025-12-20T19:48:03.000Z","updated_at":"2025-12-20T20:02:30.940Z","closed_at":"2025-12-20T20:02:30.940Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjepneb3e6h","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjf9s8wtmt1","title":"Test cell from debug session","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-21T05:11:41.597Z","updated_at":"2025-12-21T05:13:10.413Z","closed_at":"2025-12-21T05:13:10.413Z","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjf9zd9ovwf","title":"Migration runner with schema validation","status":"closed","priority":0,"issue_type":"task","created_at":"2025-12-21T05:17:13.836Z","updated_at":"2025-12-21T05:41:15.798Z","closed_at":"2025-12-21T05:41:15.798Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjf9zd9kgo7","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjf9zd9zuyq","title":"Integration tests: hive_* tools (9 tools)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-21T05:17:13.847Z","updated_at":"2025-12-21T05:41:40.541Z","closed_at":"2025-12-21T05:41:40.541Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjf9zd9kgo7","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjf9zda165l","title":"Integration tests: agentmail_* tools (11 tools)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-21T05:17:13.849Z","updated_at":"2025-12-21T05:41:41.871Z","closed_at":"2025-12-21T05:41:41.871Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjf9zd9kgo7","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjf9zda2hg5","title":"Integration tests: semantic_memory_* tools (8 tools)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-21T05:17:13.850Z","updated_at":"2025-12-21T05:41:43.066Z","closed_at":"2025-12-21T05:41:43.066Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjf9zd9kgo7","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjf9zda4z0b","title":"Integration tests: swarm_* tools (24 tools)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-21T05:17:13.852Z","updated_at":"2025-12-21T05:41:44.165Z","closed_at":"2025-12-21T05:41:44.165Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjf9zd9kgo7","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjf9zda632z","title":"Integration tests: skills_* tools (9 tools)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-21T05:17:13.854Z","updated_at":"2025-12-21T05:41:16.982Z","closed_at":"2025-12-21T05:41:16.982Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjf9zd9kgo7","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjf9zda7324","title":"Integration tests: structured_* + mandate_* tools (10 tools)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-21T05:17:13.855Z","updated_at":"2025-12-21T05:41:18.306Z","closed_at":"2025-12-21T05:41:18.306Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjf9zd9kgo7","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjf9zda9lvj","title":"Integration tests: repo_* tools (5 tools)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-21T05:17:13.857Z","updated_at":"2025-12-21T05:41:19.312Z","closed_at":"2025-12-21T05:41:19.312Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjf9zd9kgo7","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjf9zd9rprs","title":"Convert streams subsystem to Drizzle queries","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-21T05:17:13.839Z","updated_at":"2025-12-21T16:21:02.703Z","closed_at":"2025-12-21T16:21:02.703Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjf9zd9kgo7","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjf9zd9uul8","title":"Convert memory subsystem to Drizzle queries","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-21T05:17:13.842Z","updated_at":"2025-12-21T16:21:03.936Z","closed_at":"2025-12-21T16:21:03.936Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjf9zd9kgo7","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjf9zd9vceg","title":"Convert hive subsystem to Drizzle queries","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-21T05:17:13.843Z","updated_at":"2025-12-21T17:24:31.341Z","closed_at":"2025-12-21T17:24:31.341Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjf9zd9kgo7","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjfxpg2wbk8","title":"Port DurableLock to libSQL","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-21T16:21:21.704Z","updated_at":"2025-12-21T16:27:15.787Z","closed_at":"2025-12-21T16:27:15.787Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjfxpg2p165","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjfxpg2zg9f","title":"Port DurableDeferred to libSQL","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-21T16:21:21.707Z","updated_at":"2025-12-21T16:37:40.796Z","closed_at":"2025-12-21T16:37:40.796Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjfxpg2p165","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjfxpg31hwz","title":"Port DurableCursor to libSQL","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-21T16:21:21.709Z","updated_at":"2025-12-21T16:37:42.151Z","closed_at":"2025-12-21T16:37:42.151Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjfxpg2p165","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjfxpg33y71","title":"Port DurableMailbox and ask pattern to libSQL","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-21T16:21:21.711Z","updated_at":"2025-12-21T16:48:17.096Z","closed_at":"2025-12-21T16:48:17.096Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjfxpg2p165","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjfxpg35hv2","title":"Remove PGLite from streams/index.ts exports","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-21T16:21:21.713Z","updated_at":"2025-12-21T17:24:33.638Z","closed_at":"2025-12-21T17:24:33.638Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjfxpg2p165","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjfznai9mco","title":"Add Drizzle Kit migrations","description":"Use drizzle-kit for proper schema migrations instead of manual CREATE TABLE IF NOT EXISTS.\n\nBenefits:\n- Automatic migration generation from schema changes\n- Version tracking\n- Rollback support\n- Type-safe migrations\n\nWould replace the current ad-hoc migration logic in libsql-schema.ts.","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-21T17:15:40.401Z","updated_at":"2025-12-21T17:15:40.401Z","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjfzgw9c7gd","title":"Fix: SQLITE_ERROR no such column: stream in hive_create_epic","description":"When calling hive_create_epic, get error: SQLITE_ERROR: no such column: stream\n\nContext:\n- Happens when creating epic in a project\n- swarmmail_init may be reusing wrong project context\n- Schema migration may not have run on hive database\n\nLikely causes:\n1. Schema migration not run on hive SQLite database\n2. Wrong database being accessed (project path mismatch)\n3. cursors table schema change (stream column) not applied to existing DBs\n\nRelated to PGLite→libSQL migration - the cursors table schema changed from stream_id to stream column.","status":"closed","priority":0,"issue_type":"bug","created_at":"2025-12-21T17:10:42.000Z","updated_at":"2025-12-21T17:26:06.716Z","closed_at":"2025-12-21T17:26:06.716Z","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjg00gnvf8y","title":"Fix P0: cursors table schema migration (stream column)","status":"closed","priority":0,"issue_type":"task","created_at":"2025-12-21T17:25:54.907Z","updated_at":"2025-12-21T17:32:38.681Z","closed_at":"2025-12-21T17:32:38.681Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjg00gnmwui","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjg00go0fga","title":"Fix agentmail_release integration tests (3 failing)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-21T17:25:54.912Z","updated_at":"2025-12-21T17:37:03.773Z","closed_at":"2025-12-21T17:37:03.773Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjg00gnmwui","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjg00go89jn","title":"Fix swarm_checkpoint integration tests (2 failing)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-21T17:25:54.920Z","updated_at":"2025-12-21T17:37:06.462Z","closed_at":"2025-12-21T17:37:06.462Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjg00gnmwui","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjg01a7xgtu","title":"Bug: hive_update cannot close cells (CHECK constraint fails)","description":"When calling hive_update with status='closed', get error:\n\n```\nSQLITE_CONSTRAINT_CHECK: CHECK constraint failed: (status = 'closed') = (closed_at IS NOT NULL)\n```\n\nRoot cause: The beads table has a CHECK constraint requiring closed_at to be set when status='closed'. hive_update doesn't set closed_at when changing status to closed.\n\nFix: Either:\n1. hive_update should set closed_at = NOW() when status='closed'\n2. Or hive_update should reject status='closed' and require hive_close instead\n\nLocation: packages/swarm-mail/src/hive/adapter.ts (updateCell method)","status":"closed","priority":0,"issue_type":"bug","created_at":"2025-12-21T17:26:33.213Z","updated_at":"2025-12-21T17:32:40.860Z","closed_at":"2025-12-21T17:32:40.860Z","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjg00gnmwui","title":"Fix P0 Schema Bug + Integration Tests + Effect Primitives","description":"Sequential risk-based approach: Fix cursors schema migration bug (P0), then fix 6 failing integration tests, consolidate duplicate schemas, and integrate DurableLock/DurableDeferred into swarm coordination.","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-12-21T17:25:54.898Z","updated_at":"2025-12-21T17:48:25.022Z","closed_at":"2025-12-21T17:48:25.022Z","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjg00goagh1","title":"Consolidate duplicate schema definitions","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-21T17:25:54.922Z","updated_at":"2025-12-21T17:45:23.718Z","closed_at":"2025-12-21T17:45:23.718Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjg00gnmwui","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjg00god17i","title":"Port DurableLock to libSQL/DatabaseAdapter","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-21T17:25:54.925Z","updated_at":"2025-12-21T17:48:17.068Z","closed_at":"2025-12-21T17:48:17.068Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjg00gnmwui","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjg00gogwct","title":"Port DurableDeferred to libSQL/DatabaseAdapter","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-21T17:25:54.928Z","updated_at":"2025-12-21T17:48:18.268Z","closed_at":"2025-12-21T17:48:18.268Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjg00gnmwui","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjf9zd9kgo7","title":"Drizzle Migration + Plugin Integration Tests","description":"Convert all raw SQL to Drizzle ORM with proper migrations. Add happy-path integration tests for all 93 plugin tools. TDD approach: test first, then implement.\n\nBranch: feat/drizzle-migration-and-tests\n\n## Phase 1: Foundation (sequential)\n- Migration runner with schema validation\n\n## Phase 2: Drizzle Conversion (parallel after Phase 1)\n- Convert streams subsystem\n- Convert memory subsystem  \n- Convert hive subsystem\n\n## Phase 3: Cleanup (after Phase 2)\n- Remove duplicate schema definitions\n\n## Phase 4: Integration Tests (parallel, some depend on Phase 2)\n- hive_* tools (9)\n- agentmail_* tools (11)\n- semantic_memory_* tools (8)\n- swarm_* tools (24)\n- skills_* tools (9)\n- structured_* + mandate_* tools (10)\n- repo_* tools (5)","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-12-21T05:17:13.832Z","updated_at":"2025-12-21T18:01:12.967Z","closed_at":"2025-12-21T18:01:12.967Z","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjf9zd9xs46","title":"Remove duplicate schema definitions","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-21T05:17:13.845Z","updated_at":"2025-12-21T18:01:04.308Z","closed_at":"2025-12-21T18:01:04.308Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjf9zd9kgo7","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjfvn2w3yuv","title":"Drizzle Migration Phase 2: Fix Tests + Hive Conversion","description":"Complete Drizzle migration for swarm-mail package.\n\n## Context\n- Streams subsystem: ✅ Done (wrappers added)\n- Memory subsystem: ✅ Done (already uses Drizzle)\n- Hive subsystem: ❌ Still uses DatabaseAdapter with raw SQL\n\n## Approach\nKeep HiveAdapter interface, rewrite internals to use Drizzle ORM.\nFollow course-builder adapter-drizzle pattern: interface in core, Drizzle implementation under the hood.\n\n## Shared Context for Workers\n- Use `toSwarmDb()` to convert DatabaseAdapter → SwarmDb (Drizzle client)\n- Create wrapper functions matching old signatures for backward compat\n- Keep complex CTEs as raw SQL via `sql.raw()` if Drizzle can't express them\n- Schema source of truth: `packages/swarm-mail/src/db/schema/hive.ts`\n\n## Dependencies\n- Task 1 (fix tests) unblocks CI\n- Task 2 (hive conversion) is the main work\n- Task 3 (schema consolidation) depends on Task 2","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-12-21T15:23:32.067Z","updated_at":"2025-12-21T18:01:05.723Z","closed_at":"2025-12-21T18:01:05.723Z","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjfvn2w82v6","title":"Fix 6 failing integration tests (CI blocker)","status":"closed","priority":0,"issue_type":"task","created_at":"2025-12-21T15:23:32.072Z","updated_at":"2025-12-21T18:00:54.686Z","closed_at":"2025-12-21T18:00:54.686Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjfvn2w3yuv","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjfvn2wanib","title":"Convert hive/store.ts to Drizzle","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-21T15:23:32.074Z","updated_at":"2025-12-21T18:00:56.179Z","closed_at":"2025-12-21T18:00:56.179Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjfvn2w3yuv","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjfvn2wcdxt","title":"Convert hive/projections.ts to Drizzle","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-21T15:23:32.076Z","updated_at":"2025-12-21T18:00:57.636Z","closed_at":"2025-12-21T18:00:57.636Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjfvn2w3yuv","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjfvn2webre","title":"Convert hive/queries.ts to Drizzle (or keep raw SQL for complex CTEs)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-21T15:23:32.078Z","updated_at":"2025-12-21T18:00:59.516Z","closed_at":"2025-12-21T18:00:59.516Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjfvn2w3yuv","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjfvn2wggoh","title":"Convert hive/comments.ts, labels.ts, dependencies.ts to Drizzle","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-21T15:23:32.080Z","updated_at":"2025-12-21T18:01:01.046Z","closed_at":"2025-12-21T18:01:01.046Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjfvn2w3yuv","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjfvn2wiku9","title":"Consolidate duplicate schema definitions","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-21T15:23:32.082Z","updated_at":"2025-12-21T18:01:02.609Z","closed_at":"2025-12-21T18:01:02.609Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjfvn2w3yuv","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjfxpg2p165","title":"Remove PGLite, Port Effect Primitives to libSQL","description":"Complete removal of PGLite infrastructure (except migration tools), port all Effect-TS durable primitives to use libSQL/DatabaseAdapter, and integrate DurableLock + DurableDeferred into swarm worker coordination.\n\n## Context\n- Upstream source: https://github.com/durable-streams/durable-streams\n- Effect primitives: DurableLock, DurableDeferred, DurableCursor, DurableMailbox\n- Current state: primitives use getDatabase() which returns PGLite\n- Target state: primitives accept DatabaseAdapter parameter (libSQL)\n\n## Execution Order\n1. Tasks 0-2 in parallel (Lock, Deferred, Cursor)\n2. Task 3 after 0-2 (Mailbox + ask pattern)\n3. Task 4 after 3 (Remove PGLite from exports)\n4. Tasks 5-6 in parallel after 4 (Integration into swarm)","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-12-21T16:21:21.697Z","updated_at":"2025-12-21T18:05:01.905Z","closed_at":"2025-12-21T18:05:01.905Z","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjfxpg37mzq","title":"Integrate DurableLock into swarm file reservations","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-21T16:21:21.715Z","updated_at":"2025-12-21T18:05:03.058Z","closed_at":"2025-12-21T18:05:03.058Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjfxpg2p165","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjfxpg39jw6","title":"Integrate DurableDeferred into swarm task completion","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-21T16:21:21.717Z","updated_at":"2025-12-21T18:05:04.159Z","closed_at":"2025-12-21T18:05:04.159Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjfxpg2p165","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjg1elo7hfg","title":"Remove PGLite dead code from streams/index.ts","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-21T18:04:54.199Z","updated_at":"2025-12-21T18:11:33.570Z","closed_at":"2025-12-21T18:11:33.570Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjg1elo0g21","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjg1elo0g21","title":"PGLite Cleanup + Effect Primitives Integration","description":"Remove dead PGLite code from streams/index.ts, integrate DurableLock into swarm file reservations, integrate DurableDeferred into swarm task completion. YOLO for v0.31.","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-12-21T18:04:54.192Z","updated_at":"2025-12-21T18:24:36.778Z","closed_at":"2025-12-21T18:24:36.778Z","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjg1elo9uoa","title":"Integrate DurableLock into swarm file reservations","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-21T18:04:54.201Z","updated_at":"2025-12-21T18:24:34.312Z","closed_at":"2025-12-21T18:24:34.312Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjg1elo0g21","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjg1eloagne","title":"Integrate DurableDeferred into swarm task completion","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-21T18:04:54.202Z","updated_at":"2025-12-21T18:24:35.188Z","closed_at":"2025-12-21T18:24:35.188Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjg1elo0g21","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjg2uw8rcvo","title":"Consolidate per-project DBs to centralized global DB","description":"Currently each project gets its own `.opencode/streams.db` database, with fallback to `~/.opencode/streams.db`. This causes:\n\n1. **Schema drift** - Different projects have different schema versions, causing \"no such column: stream\" errors\n2. **Migration complexity** - Need to migrate each project's DB separately\n3. **Disk bloat** - Multiple copies of similar data\n4. **Cross-project queries impossible** - Can't search across all projects\n\n**Proposed solution:**\n- Single global `~/.opencode/swarm-mail.db` for all projects\n- Project isolation via `project_key` column (already exists in schema)\n- Single migration path\n- Optional per-project override for special cases\n\n**Migration path:**\n1. Add migration tool to merge existing per-project DBs into global\n2. Update `getSwarmMailLibSQL()` to prefer global DB\n3. Deprecate per-project DB creation\n4. Clean up old per-project DBs after successful migration\n\n**Related issues:**\n- \"SQLITE_ERROR: no such column: stream\" errors in tests and other sessions\n- PGLite → libSQL migration incomplete in some projects","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-12-21T18:45:34.011Z","updated_at":"2025-12-21T19:10:18.780Z","closed_at":"2025-12-21T19:10:18.780Z","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjg37qv7vim","title":"Auto-migration to centralized swarm tools database","description":"On swarmmail_init, detect old per-project DBs (.opencode/streams.db or .opencode/streams/ PGLite), migrate data to global ~/.opencode/swarm-mail.db, rename old DB to .backup with timestamp. Fast check on init, handles both libSQL and PGLite sources.\n\n## Design Decisions\n- Trigger: On swarmmail_init (natural entry point, once per session)\n- Old DB handling: Rename to .backup-<timestamp> (safe rollback)\n- Global DB: ~/.opencode/swarm-mail.db\n- Project isolation: via project_key column (already exists)\n\n## Lore (from DDIA)\n\"In most cases, a change to an application's features also requires a change to data that it stores\" - handle schema evolution gracefully, missing tables are OK.","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-12-21T18:55:33.572Z","updated_at":"2025-12-21T19:10:16.910Z","closed_at":"2025-12-21T19:10:16.910Z","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjg37qvlyi9","title":"Create complete auto-migration module","status":"closed","priority":0,"issue_type":"task","created_at":"2025-12-21T18:55:33.585Z","updated_at":"2025-12-21T19:09:14.664Z","closed_at":"2025-12-21T19:09:14.664Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjg37qv7vim","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjg37qvom6o","title":"Update getDatabasePath to use global DB","status":"closed","priority":0,"issue_type":"task","created_at":"2025-12-21T18:55:33.588Z","updated_at":"2025-12-21T19:09:16.029Z","closed_at":"2025-12-21T19:09:16.029Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjg37qv7vim","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjg37qvrqhw","title":"Integrate auto-migration into swarmmail_init","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-21T18:55:33.591Z","updated_at":"2025-12-21T19:09:17.831Z","closed_at":"2025-12-21T19:09:17.831Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjg37qv7vim","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjg37qw04am","title":"Add tests for auto-migration","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-21T18:55:33.600Z","updated_at":"2025-12-21T19:09:19.036Z","closed_at":"2025-12-21T19:09:19.036Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjg37qv7vim","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjg37qw2oq7","title":"Update exports and documentation","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-21T18:55:33.602Z","updated_at":"2025-12-21T19:10:14.566Z","closed_at":"2025-12-21T19:10:14.566Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjg37qv7vim","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjg3injmw1p","title":"Fix global DB path: ~/.config/swarm-tools/swarm.db","description":"User requested path change after initial implementation.\n\nChange from: ~/.opencode/swarm-mail.db\nChange to: ~/.config/swarm-tools/swarm.db\n\nFiles to update:\n1. packages/swarm-mail/src/streams/auto-migrate.ts - getGlobalDbPath()\n2. packages/swarm-mail/src/streams/index.ts - getDatabasePath()\n3. Any tests that reference the old path\n\nRationale: Cleaner separation from OpenCode config, follows XDG conventions.","status":"closed","priority":0,"issue_type":"task","created_at":"2025-12-21T19:04:02.482Z","updated_at":"2025-12-21T19:09:13.065Z","closed_at":"2025-12-21T19:09:13.065Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjg37qv7vim","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjg23zk1qi7","title":"Remove UBS scan from swarm_complete","description":"Remove the UBS scan step from swarm_complete. It's slowing things down and not providing value for the release.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-21T18:24:38.593Z","updated_at":"2025-12-21T19:44:05.642Z","closed_at":"2025-12-21T19:44:05.642Z","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjg59pcddrx","title":"Holistic Docs Refresh","description":"Full documentation overhaul with practical focus. OpenCode users should be running /swarm in under 1 minute.\n\nGoals:\n- Keep the \"why\" (problem statement)\n- Accurate tech stack (libSQL not PGLite, no UBS scan)\n- Terminology: beads→hive/cells throughout\n- Sick ASCII art (bee/hive/swarm theme)\n- Quotes from pdf-brain sprinkled in\n- Diagrams where useful\n- No marketing fluff, just explanation\n- Use cases front and center\n\nQuote seeds from pdf-brain:\n- \"With event sourcing, you can design an event such that it is a self-contained description of a user action.\" — Kleppmann, DDIA\n- \"ROC accepts that failures will inevitably happen... investigations aim to improve survivability\" — Release It!\n- \"Architecture boils down to the important stuff—whatever that is.\" — Fowler, PEAA\n- \"High-variability sequencing of whole-task problems\" — 4C/ID Model","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-12-21T19:53:04.141Z","updated_at":"2025-12-21T19:59:12.464Z","closed_at":"2025-12-21T19:59:12.464Z","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjg59pcltt5","title":"Homepage rewrite","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-21T19:53:04.149Z","updated_at":"2025-12-21T19:59:06.124Z","closed_at":"2025-12-21T19:59:06.124Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjg59pcddrx","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjg59pcnvlc","title":"Root README update","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-21T19:53:04.151Z","updated_at":"2025-12-21T19:59:07.923Z","closed_at":"2025-12-21T19:59:07.923Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjg59pcddrx","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjg59pcpwx4","title":"Plugin README update","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-21T19:53:04.153Z","updated_at":"2025-12-21T19:59:09.181Z","closed_at":"2025-12-21T19:59:09.181Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjg59pcddrx","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjg59pcsmey","title":"Web docs terminology sweep","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-21T19:53:04.156Z","updated_at":"2025-12-21T19:59:10.895Z","closed_at":"2025-12-21T19:59:10.895Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjg59pcddrx","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjg5hwga30a","title":"Evaluate CASS for inhousing - nuke the dep","description":"Deep dive into https://github.com/Dicklesworthstone/coding_agent_session_search\n\n**Goal:** Determine if we should bring CASS functionality in-house and eliminate the external Python dependency.\n\n**Questions to answer:**\n1. What agent session formats does it index? (Claude, Cursor, Codex, etc.)\n2. How does it build the search index? (embedding model, chunking strategy)\n3. What's the query interface? (semantic search, filters, ranking)\n4. How much of this overlaps with our semantic memory?\n5. What's unique/valuable that we'd lose without it?\n\n**If we inhouse:**\n- Scan agent session files ourselves (add to libSQL index)\n- Unify search: one `memory_find()` for both curated learnings AND historical sessions\n- Cross-agent support built into swarm-mail\n- No Python dep, no separate `cass index` command\n\n**Deliverables:**\n1. Architecture analysis doc\n2. Recommendation: inhouse vs keep dep vs hybrid\n3. If inhouse: implementation plan with effort estimate\n\n**Related:** We already have semantic-memory with libSQL + Ollama embeddings. CASS uses its own embedding pipeline. Could we unify?","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-21T19:59:26.602Z","updated_at":"2025-12-21T19:59:26.602Z","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjg5owr6vxb","title":"Fix DB adapter wiring + add integration test coverage","description":"Eliminate all \"dbOverride parameter is required\" errors by fixing code that calls swarmMail.getDatabase() expecting raw query access. The adapter pattern requires passing DatabaseAdapter explicitly to store functions. Also add integration tests to catch these issues in the future.","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-12-21T20:04:53.586Z","updated_at":"2025-12-21T21:02:57.661Z","closed_at":"2025-12-21T21:02:57.661Z","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjg5owrdvkk","title":"Fix swarm-mail internals - remove getDatabase() requirement from store/projections","description":"REDO with proper TDD. Tests FIRST, then implementation. Previous attempt skipped to implementation.","status":"closed","priority":0,"issue_type":"task","created_at":"2025-12-21T20:04:53.593Z","updated_at":"2025-12-21T20:21:55.877Z","closed_at":"2025-12-21T20:21:55.877Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjg5owr6vxb","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjg5owrf7bf","title":"Fix plugin runtime - update swarm-orchestrate.ts, hive.ts, memory-tools.ts, swarm-mail.ts","status":"closed","priority":0,"issue_type":"task","created_at":"2025-12-21T20:04:53.595Z","updated_at":"2025-12-21T20:32:30.032Z","closed_at":"2025-12-21T20:32:30.032Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjg5owr6vxb","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjg5owrhr3v","title":"Update test files using old getDatabase() pattern","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-21T20:04:53.597Z","updated_at":"2025-12-21T20:46:42.634Z","closed_at":"2025-12-21T20:46:42.634Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjg5owr6vxb","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjg5owrjo4f","title":"Add tool-layer integration tests that verify adapter wiring end-to-end","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-21T20:04:53.599Z","updated_at":"2025-12-21T20:54:41.568Z","closed_at":"2025-12-21T20:54:41.568Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjg5owr6vxb","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjg6oywchz2","title":"Add mandatory coordinator review loop after worker completion","description":"The coordinator prompt in AGENTS.md mentions swarm_review but doesn't COMMAND it after every worker return.\n\nNeed to:\n1. Update swarm-prompts.ts to add a COORDINATOR_REVIEW_LOOP constant\n2. Update swarm_spawn_subtask to include post-completion instructions for coordinator\n3. Update bin/swarm.ts coordinator prompt to MANDATE the review loop\n4. Update global-skills/swarm-coordination/SKILL.md with explicit review requirements\n\nThe pattern should be:\n```\nTask(worker) returns → IMMEDIATELY:\n1. swarmmail_inbox() - check for worker messages\n2. swarm_review(project_key, epic_id, task_id, files_touched)\n3. Review the diff against epic goals\n4. swarm_review_feedback(status=\"approved|needs_changes\")\n5. ONLY THEN spawn next worker or complete\n```","status":"closed","priority":0,"issue_type":"task","created_at":"2025-12-21T20:32:55.980Z","updated_at":"2025-12-21T21:02:51.097Z","closed_at":"2025-12-21T21:02:51.097Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjg5owr6vxb","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjggwznl7gx","title":"Add PGlite deprecation warnings, remove in next major","description":"## Context\nPGlite migration code remains for backward compatibility but libSQL is now the only supported database.\n\n## What to do\n\n### Phase 1: Add Deprecation Warnings (this release)\n- `wrapPGlite()` in pglite.ts - add console.warn on first call\n- `toDrizzleDb()` PGlite branch - add console.warn when PGlite detected\n- `migratePGliteToLibSQL()` - add warning that this is last supported version\n- Update CHANGELOG with deprecation notice\n\n### Phase 2: Remove in Next Major (v1.0 or v0.32)\n- Remove pglite.ts entirely\n- Remove PGlite branch from toDrizzleDb()\n- Remove migrate-pglite-to-libsql.ts\n- Remove memory/migrate-legacy.ts PGlite code\n- Remove @electric-sql/pglite from dependencies\n- Remove drizzle-orm/pglite imports\n\n## Files affected\n- packages/swarm-mail/src/pglite.ts\n- packages/swarm-mail/src/libsql.convenience.ts\n- packages/swarm-mail/src/migrate-pglite-to-libsql.ts\n- packages/swarm-mail/src/memory/migrate-legacy.ts\n- packages/swarm-mail/package.json (remove dep)","status":"open","priority":2,"issue_type":"chore","created_at":"2025-12-22T01:19:06.369Z","updated_at":"2025-12-22T01:19:06.369Z","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjgh4b3kmi1","title":"Fix PGLite typecheck errors in CI","description":"CI failing: Cannot find module '@electric-sql/pglite'. Migration files have static imports but PGLite is devDependency.\n\nFix: Convert static imports to dynamic imports in:\n- src/memory/migrate-legacy.ts (lines 146-147, 305-306)\n- src/migrate-pglite-to-libsql.ts (lines 93-94)\n- src/pglite.ts (line 10, plus fix implicit any on line 35)\n\nUse pattern from semantic memory: dynamic import inside functions, type assertions for results.","status":"closed","priority":0,"issue_type":"bug","created_at":"2025-12-22T01:24:47.792Z","updated_at":"2025-12-22T01:27:32.279Z","closed_at":"2025-12-22T01:27:32.279Z","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjgha1ijy85","title":"Add @ts-ignore to PGLite dynamic imports","description":"Dynamic imports still get type-checked by TypeScript. Need to add @ts-ignore comments above each dynamic import line.\n\nFiles:\n- src/memory/migrate-legacy.ts (lines 146, 147, 305, 306)\n- src/migrate-pglite-to-libsql.ts (lines 93, 94)\n\nPattern:\n```typescript\n// @ts-ignore - PGLite is optional, loaded dynamically for migration only\nconst { PGlite } = (await import(\"@electric-sql/pglite\")) as any;\n// @ts-ignore - PGLite vector extension\nconst { vector } = (await import(\"@electric-sql/pglite/vector\")) as any;\n```","status":"closed","priority":0,"issue_type":"bug","created_at":"2025-12-22T01:29:15.307Z","updated_at":"2025-12-22T01:30:59.948Z","closed_at":"2025-12-22T01:30:59.948Z","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjghm2c8rkt","title":"Fix migrate-legacy.test.ts PGLite import","description":"Test file still has static PGLite import:\n```\nerror: Cannot find module '@electric-sql/pglite' from '/home/runner/work/swarm-tools/swarm-tools/packages/swarm-mail/src/memory/migrate-legacy.test.ts'\n```\n\nNeed to either:\n1. Skip the test when PGLite isn't available\n2. Use dynamic import in the test file too\n3. Mark the test as integration-only","status":"closed","priority":0,"issue_type":"bug","created_at":"2025-12-22T01:38:36.248Z","updated_at":"2025-12-22T01:43:02.311Z","closed_at":"2025-12-22T01:43:02.311Z","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjghm3oyxgp","title":"Fix cell ID prefix test - package.json name not found","description":"Test failing:\n```\nExpected substring or pattern: /^swarm-mail-[-a-z0-9]+-[a-z0-9]+$/\nReceived: \"cell--d02u8-mjghd0qj2bg\"\n```\n\nThe generateBeadId function isn't finding the package.json name in CI. The prefix is empty, resulting in `cell--` instead of `swarm-mail-`.","status":"closed","priority":0,"issue_type":"bug","created_at":"2025-12-22T01:38:38.002Z","updated_at":"2025-12-22T01:43:03.048Z","closed_at":"2025-12-22T01:43:03.048Z","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjgi42mfkmv","title":"Fix agent-mail.test.ts - checkHealth and DurableLock tests using deprecated API","description":"Tests in agent-mail.test.ts are calling deprecated `checkHealth()` which now throws:\n```\n[agent-mail] checkHealth() has been removed. PGlite infrastructure is deprecated.\n```\n\nAffected tests:\n- checkHealth > returns healthy when database is accessible\n- checkHealth > returns stats about the store\n- DurableLock Integration > uses DurableLock for file reservation locking\n- DurableLock Integration > releases DurableLock when files are released\n- DurableLock Integration > respects lock expiry (TTL)\n- reserveAgentFiles tests (multiple)\n- releaseAgentFiles tests (multiple)\n\nOptions:\n1. Update tests to use createSwarmMailAdapter() pattern\n2. Skip these tests with a TODO to update later\n3. Restore checkHealth with adapter-based implementation\n\nGiven time pressure, option 2 (skip with TODO) is fastest.","status":"closed","priority":0,"issue_type":"bug","created_at":"2025-12-22T01:52:36.423Z","updated_at":"2025-12-22T01:56:25.828Z","closed_at":"2025-12-22T01:56:25.828Z","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjgicv66eyc","title":"Fix missing resetDatabase/closeDatabase exports in test files","description":"Two test files import functions that were removed:\n- debug.test.ts imports resetDatabase\n- projections.test.ts imports closeDatabase\n\nThese functions were removed with PGLite. Need to either:\n1. Skip these tests\n2. Update to use adapter pattern","status":"closed","priority":0,"issue_type":"bug","created_at":"2025-12-22T01:59:26.670Z","updated_at":"2025-12-22T02:05:24.529Z","closed_at":"2025-12-22T02:05:24.529Z","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjgmdsjknsx","title":"Fix SQL injection in cursor.ts - use parameterized queries","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-22T03:52:08.385Z","updated_at":"2025-12-22T03:52:08.385Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjgmdsjc88p","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjgmdsjosz1","title":"Fix SQL injection in lock.ts - use parameterized queries","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-22T03:52:08.388Z","updated_at":"2025-12-22T03:52:08.388Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjgmdsjc88p","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjgmw8ad8da","title":"Fix swarm-mail.test.ts to use adapter pattern","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-22T04:06:28.597Z","updated_at":"2025-12-22T04:06:28.597Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjgmw89cjom","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjgmw8ah72p","title":"Clean test artifacts and commit all fixes","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-22T04:06:28.601Z","updated_at":"2025-12-22T04:06:28.601Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjgmw89cjom","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjgotvvoh8z","title":"Fix DatabaseAdapter import in agent-mail.ts (build broken)","description":"**CRITICAL: Build is broken**\n\nThe worker's changes to agent-mail.ts imported DatabaseAdapter from the wrong path:\n```typescript\nimport type { DatabaseAdapter } from \"../adapter\";  // WRONG\n```\n\nShould be:\n```typescript\nimport type { DatabaseAdapter } from \"../types/database\";  // CORRECT\n```\n\nError:\n```\nsrc/streams/agent-mail.ts(24,15): error TS2459: Module '\"../adapter\"' declares 'DatabaseAdapter' locally, but it is not exported.\n```\n\nThis blocks the entire release - typecheck and build both fail.","status":"closed","priority":0,"issue_type":"bug","created_at":"2025-12-22T05:00:38.436Z","updated_at":"2025-12-22T05:01:11.424Z","closed_at":"2025-12-22T05:01:11.424Z","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjgpm1e5zjq","title":"sendSwarmMessage needs dbAdapter parameter for test isolation","description":"**Problem:** `sendSwarmMessage` in swarm-review.ts creates its own LibSQLAdapter internally, which fails with \"URL_INVALID\" for paths like `~/.config/swarm-tools/swarm.db`.\n\n**Impact:** \n- swarm_review_feedback integration tests can't use in-memory databases\n- Tests are skipped in swarm-review.integration.test.ts\n\n**Root cause:**\nsendSwarmMessage calls getSwarmMailLibSQL() without accepting a dbAdapter parameter, so it can't use the test's in-memory adapter.\n\n**Fix options:**\n1. Add dbAdapter parameter to swarm_review_feedback (breaking change)\n2. Make sendSwarmMessage use adapter cache (global state)\n3. Use file:// URLs for all database paths\n\n**Files:**\n- packages/opencode-swarm-plugin/src/swarm-review.ts\n- packages/opencode-swarm-plugin/src/swarm-review.integration.test.ts","status":"open","priority":2,"issue_type":"bug","created_at":"2025-12-22T05:22:31.949Z","updated_at":"2025-12-22T05:22:31.949Z","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjgqqmtgx08","title":"swarmmail_health uses deprecated checkHealth() that was removed","description":"**Problem:** `swarmmail_health` tool calls the deprecated `checkHealth()` function that was removed during PGlite cleanup.\n\n**Error:**\n```\nHealth check failed: [agent-mail] checkHealth() has been removed. PGlite infrastructure is deprecated. Use createSwarmMailAdapter() and call adapter.checkHealth() instead.\n```\n\n**Expected:** Health check should use the new adapter pattern, not the removed function.\n\n**Fix:** Update swarmmail_health in swarm-mail.ts to use `createSwarmMailAdapter().checkHealth()` or equivalent libSQL health check.","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-22T05:54:05.956Z","updated_at":"2025-12-22T06:13:21.000Z","closed_at":"2025-12-22T06:13:21.000Z","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjgqqp1izbr","title":"swarmmail_inbox fails with \"no such table: messages\" - schema not initialized","description":"**Problem:** `swarmmail_inbox` fails because the messages table doesn't exist.\n\n**Error:**\n```\nFailed to fetch inbox: SQLITE_ERROR: no such table: messages\n```\n\n**Expected:** Schema should be auto-initialized when swarmmail tools are used, or `swarmmail_init` should ensure schema exists.\n\n**Root cause:** The libSQL schema initialization isn't being called before querying. Either:\n1. `swarmmail_init` doesn't create the schema\n2. `swarmmail_inbox` doesn't ensure schema exists before querying\n\n**Fix:** Ensure `createLibSQLStreamsSchema()` is called during init or before first query.","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-22T05:54:08.838Z","updated_at":"2025-12-22T06:13:22.317Z","closed_at":"2025-12-22T06:13:22.317Z","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjgmdsjc88p","title":"Fix PR #54 review comments","description":"Address CodeRabbit review comments:\n1. SQL injection vulnerabilities in cursor.ts and lock.ts\n2. Test pollution in .hive/memories.jsonl","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-12-22T03:52:08.376Z","updated_at":"2025-12-22T16:45:20.225Z","closed_at":"2025-12-22T16:45:20.225Z","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjgmdsjq0gb","title":"Remove test artifacts from .hive/memories.jsonl","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-22T03:52:08.390Z","updated_at":"2025-12-22T16:45:25.538Z","closed_at":"2025-12-22T16:45:25.538Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjgmdsjc88p","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjgmw89cjom","title":"PR #54: Fix skipped tests and resolve CodeRabbit comments","description":"Delete deprecated test files, fix/unskip remaining tests, commit SQL injection fixes, fix double file: prefix bug, clean test artifacts, push and resolve PR comments","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-12-22T04:06:28.560Z","updated_at":"2025-12-22T16:45:21.082Z","closed_at":"2025-12-22T16:45:21.082Z","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjgmw89p9re","title":"Delete deprecated debug module and tests","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-22T04:06:28.573Z","updated_at":"2025-12-22T16:45:26.311Z","closed_at":"2025-12-22T16:45:26.311Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjgmw89cjom","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjgmw89uekd","title":"Delete deprecated test files (migrations.test.ts, projections.test.ts)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-22T04:06:28.578Z","updated_at":"2025-12-22T16:45:27.218Z","closed_at":"2025-12-22T16:45:27.218Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjgmw89cjom","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjgmw8a3wqf","title":"Fix double file: prefix in store-drizzle.ts","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-22T04:06:28.587Z","updated_at":"2025-12-22T16:45:28.218Z","closed_at":"2025-12-22T16:45:28.218Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjgmw89cjom","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjgmw8a89uc","title":"Fix agent-mail.test.ts skipped reservation tests","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-22T04:06:28.592Z","updated_at":"2025-12-22T16:45:28.958Z","closed_at":"2025-12-22T16:45:28.958Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjgmw89cjom","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjhdvwcbb5f","title":"Clean test artifacts from .hive/","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-22T16:42:02.747Z","updated_at":"2025-12-22T16:44:06.368Z","closed_at":"2025-12-22T16:44:06.368Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjhdvwbu2iv","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjhdvwbu2iv","title":"PR #54 Final Cleanup","description":"Clean up test artifacts, fix test isolation, verify URL normalization fix, close orphan cells.\n\nContext from semantic memory:\n- sendSwarmMessage was failing with URL_INVALID for bare paths - FIXED by URL normalization in createLibSQLAdapter\n- Test isolation issue: tests writing to prod .hive/ instead of temp directories\n- 3 \"E2E Test Epic\" artifacts + 6 subtasks need cleanup from issues.jsonl\n- 1 test memory needs removal from memories.jsonl","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-12-22T16:42:02.730Z","updated_at":"2025-12-22T16:53:23.084Z","closed_at":"2025-12-22T16:53:23.084Z","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjhdvwcftl0","title":"Fix test isolation - prevent tests writing to prod .hive/","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-22T16:42:02.752Z","updated_at":"2025-12-22T16:53:15.728Z","closed_at":"2025-12-22T16:53:15.728Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjhdvwbu2iv","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjhdvwcigod","title":"Verify sendSwarmMessage URL fix and unskip tests","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-22T16:42:02.754Z","updated_at":"2025-12-22T16:53:16.991Z","closed_at":"2025-12-22T16:53:16.991Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjhdvwbu2iv","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjhdvwckiyk","title":"Close duplicate/orphan cells and sync","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-22T16:42:02.756Z","updated_at":"2025-12-22T16:53:17.768Z","closed_at":"2025-12-22T16:53:17.768Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjhdvwbu2iv","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjhef7g97ss","title":"Fix getInbox returns empty in swarm-review integration tests","description":"Bug: swarm-review.integration.test.ts tests pass sendSwarmMessage but getInbox returns empty.\n\nHypothesis from semantic memory:\n- sendSwarmMessage creates its own LibSQLAdapter\n- Test uses a different in-memory adapter instance\n- Messages written to one DB, read from another = empty\n\nTDD approach:\n1. Write/unskip failing test that reproduces the bug\n2. Trace the adapter creation path\n3. Fix the adapter sharing issue\n4. Verify test passes","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-12-22T16:57:03.609Z","updated_at":"2025-12-22T17:10:48.958Z","closed_at":"2025-12-22T17:10:48.958Z","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjhef7gh5cy","title":"Investigate and fix getInbox empty bug with TDD","status":"closed","priority":0,"issue_type":"task","created_at":"2025-12-22T16:57:03.617Z","updated_at":"2025-12-22T17:10:48.320Z","closed_at":"2025-12-22T17:10:48.320Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjhef7g97ss","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjhfac87zak","title":"Resolve PR #54 Comments + Create pr-triage Skill","description":"Hybrid approach: fix code issues with TDD, reply won't-fix to minor/style issues, create reusable pr-triage skill for future PR reviews. All 5 subtasks can run in parallel.","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-12-22T17:21:16.135Z","updated_at":"2025-12-22T17:30:53.519Z","closed_at":"2025-12-22T17:30:53.519Z","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjhfac8da6s","title":"Create pr-triage skill with context-efficient patterns","description":"Create a new skill at .opencode/skills/pr-triage/ (PROJECT-LEVEL, not global) that teaches agents how to efficiently triage and respond to PR comments.\n\nKEY REQUIREMENTS:\n1. SKILL.md must include:\n   - Context-efficient workflow: fetch metadata first (id, path, line, severity), only fetch full body when needed\n   - gh API patterns for listing comments without blowing context\n   - Triage categories: fix-with-code, won't-fix, tracked-in-cell\n   - Response templates for each category\n   - CodeRabbit-specific patterns (severity markers, proposed fixes)\n\n2. references/gh-api-patterns.md with:\n   - Compact jq queries for comment metadata\n   - Thread detection (in_reply_to_id)\n   - Severity extraction from CodeRabbit format\n   - Reply posting via gh api\n\nUse skills_create tool with scope=\"project\" to create the skill, then add content.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-22T17:21:16.141Z","updated_at":"2025-12-22T17:28:57.715Z","closed_at":"2025-12-22T17:28:57.715Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjhfac87zak","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjhfac8fxvn","title":"Reply to .hive/issues.jsonl comments (already cleaned)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-22T17:21:16.143Z","updated_at":"2025-12-22T17:28:59.215Z","closed_at":"2025-12-22T17:28:59.215Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjhfac87zak","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjhfac8ielf","title":"Fix adapter.test.ts - add closed_reason verification (TDD)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-22T17:21:16.146Z","updated_at":"2025-12-22T17:29:00.141Z","closed_at":"2025-12-22T17:29:00.141Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjhfac87zak","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjhfac8kn2t","title":"Fix agent-mail.ts DurableLock error handling (TDD)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-22T17:21:16.148Z","updated_at":"2025-12-22T17:29:01.286Z","closed_at":"2025-12-22T17:29:01.286Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjhfac87zak","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjhfac8lnmh","title":"Reply won't-fix to minor/style comments","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-22T17:21:16.149Z","updated_at":"2025-12-22T17:29:02.301Z","closed_at":"2025-12-22T17:29:02.301Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjhfac87zak","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjhgw0g8l1v","title":"Holistic Docs Update - Human-Forward, Happy Path First","description":"Full docs refresh post-v0.32 (Drizzle migration). Focus on human-forward content with happy path front and center. Update all READMEs and docs site to reflect libSQL storage, 95% test coverage, coordinator review gate, and other v0.31-0.32 changes.","status":"open","priority":1,"issue_type":"epic","created_at":"2025-12-22T18:06:06.920Z","updated_at":"2025-12-22T18:06:06.920Z","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjhgw0ge029","title":"Update root README - human-forward quickstart","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-22T18:06:06.926Z","updated_at":"2025-12-22T18:06:06.926Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjhgw0g8l1v","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjhgw0ggt00","title":"Update opencode-swarm-plugin README - plugin quickstart","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-22T18:06:06.928Z","updated_at":"2025-12-22T18:06:06.928Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjhgw0g8l1v","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjhgw0gie5o","title":"Update swarm-mail README - library usage","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-22T18:06:06.930Z","updated_at":"2025-12-22T18:06:06.930Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjhgw0g8l1v","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjhgw0gk8wh","title":"Update docs site quickstart.mdx - THE main doc","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-22T18:06:06.932Z","updated_at":"2025-12-22T18:06:06.932Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjhgw0g8l1v","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjhgw0godfy","title":"Update docs site index.mdx - landing page","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-22T18:06:06.936Z","updated_at":"2025-12-22T18:06:06.936Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjhgw0g8l1v","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjhgw0gqqo8","title":"Create CHANGELOG.md from changesets","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-22T18:06:06.938Z","updated_at":"2025-12-22T18:06:06.938Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjhgw0g8l1v","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjhji3rrl06","title":"Observability Research Spike - ADRs","description":"Research spike to explore observability options for swarm tools. Output: 3 focused ADRs covering runtime visibility, post-hoc analysis, and developer debugging. No production code - design docs and feasibility assessment only.","status":"open","priority":1,"issue_type":"epic","created_at":"2025-12-22T19:19:16.887Z","updated_at":"2025-12-22T19:19:16.887Z","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjhji3rzhum","title":"ADR: Post-Hoc Analysis - Traces, Analytics & Pattern Extraction","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-22T19:19:16.895Z","updated_at":"2025-12-22T19:19:16.895Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjhji3rrl06","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjhji3s2pb3","title":"ADR: Developer Debugging - Verbose Modes, Replay & State Dumps","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-22T19:19:16.898Z","updated_at":"2025-12-22T19:19:16.898Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjhji3rrl06","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjhji3rxvs0","title":"ADR: Runtime Visibility - Live Dashboards & Status","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-22T19:19:16.893Z","updated_at":"2025-12-22T19:24:49.977Z","closed_at":"2025-12-22T19:24:49.977Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjhji3rrl06","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjhjpv5nomh","title":"Add deprecation warnings to skills_list, skills_use, skills_read, skills_execute","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-22T19:25:18.971Z","updated_at":"2025-12-22T19:29:04.031Z","closed_at":"2025-12-22T19:29:04.031Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjhjpv5hxwu","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjhjpv5qo58","title":"Audit bundled skills for Agent Skills spec compliance","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-22T19:25:18.974Z","updated_at":"2025-12-22T19:29:05.347Z","closed_at":"2025-12-22T19:29:05.347Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjhjpv5hxwu","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjhjpv5rt60","title":"Update tests for deprecated tools","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-22T19:25:18.975Z","updated_at":"2025-12-22T19:35:17.543Z","closed_at":"2025-12-22T19:35:17.543Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjhjpv5hxwu","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjhk4kkh975","title":"Implement Observability Stack (from ADRs)","description":"## Observability Implementation Plan\n\nBased on research spike ADRs:\n- `.hive/analysis/observability-runtime-visibility.md`\n- `.hive/analysis/observability-post-hoc-analysis.md`\n- `.hive/analysis/observability-developer-debugging.md`\n\n### Key Insight\nEvent sourcing is 80% of the solution. We have 17+ event types, distributed tracing built-in (epic_id = trace_id, bead_id = span_id), and libSQL for queries. We need **diagnostic views**, not new infrastructure.\n\n---\n\n## Proposed Phases\n\n### Phase 1: Error Enrichment + Verbose Logging (3 days)\n- [ ] Structured error context (file, line, agent, epic, recent events)\n- [ ] DEBUG=swarm:* environment variable filtering\n- [ ] Error suggestions based on common patterns\n- **Value:** Immediate debugging improvement, low effort\n\n### Phase 2: SQL CLI for Analytics (1 week)\n- [ ] `swarm query` CLI command with SQL interface\n- [ ] 10 pre-built queries (failed decompositions, duration by strategy, file conflicts)\n- [ ] Output formats: table, JSON, CSV\n- **Value:** \"Why did this fail?\" answerable without raw SQL\n\n### Phase 3: Terminal UI Dashboard (1-2 weeks)\n- [ ] blessed-contrib live dashboard\n- [ ] Worker status, progress bars, file locks, recent messages\n- [ ] Multi-swarm view (tabs or split)\n- **Value:** Real-time visibility without polling tools manually\n\n### Phase 4: Event Replay CLI (1 day)\n- [ ] `swarm replay <epic-id>` command\n- [ ] Replay events to stdout with timing\n- [ ] Filter by event type, agent, time range\n- **Value:** Reproduce failures locally (within LLM non-determinism)\n\n### Phase 5: Export Formats (1 week)\n- [ ] OpenTelemetry trace export\n- [ ] CSV export for spreadsheet analysis\n- [ ] JSON export for external tools\n- **Value:** Integration with existing observability stacks\n\n### Phase 6: Web Dashboard (3-4 weeks) - DEFERRED\n- [ ] React/Next.js dashboard\n- [ ] Timeline visualization\n- [ ] Dependency graphs\n- **Value:** Rich visualization, multi-user access\n- **Defer until:** Multi-swarm scenarios proven in production\n\n---\n\n## Success Criteria\n- [ ] Can answer \"why did epic X fail?\" in <2 minutes\n- [ ] Can see swarm progress in real-time without polling\n- [ ] Can export traces to external tools\n- [ ] No context bloat from verbose logging\n\n## References\n- ADR: Runtime Visibility → Terminal UI + structured logs\n- ADR: Post-Hoc Analysis → SQL CLI → exports → visualization  \n- ADR: Developer Debugging → replay + state dumps + error enrichment","status":"open","priority":1,"issue_type":"epic","created_at":"2025-12-22T19:36:45.089Z","updated_at":"2025-12-22T19:36:45.089Z","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjhjpv5hxwu","title":"Deprecate skills system for OpenCode native compatibility","description":"Soft deprecate discovery/loading tools (skills_list, skills_use, skills_read, skills_execute) with warnings. Keep authoring tools. Ensure bundled skills are spec-compliant.","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-12-22T19:25:18.965Z","updated_at":"2025-12-22T19:37:53.190Z","closed_at":"2025-12-22T19:37:53.190Z","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjhjpv5t7z5","title":"Create changeset for deprecation","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-22T19:25:18.977Z","updated_at":"2025-12-22T19:37:44.912Z","closed_at":"2025-12-22T19:37:44.912Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjhjpv5hxwu","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjhkiumsuk1","title":"swarm-db CLI Entry Point and Commands","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-22T19:47:51.316Z","updated_at":"2025-12-22T19:47:51.316Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjhkiuletid","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjhkiulp1uv","title":"Structured Error Classes with Context Enrichment","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-22T19:47:51.277Z","updated_at":"2025-12-22T19:58:39.893Z","closed_at":"2025-12-22T19:58:39.893Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjhkiuletid","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjhkiulwzvh","title":"Verbose Logging with DEBUG Environment Variable","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-22T19:47:51.284Z","updated_at":"2025-12-22T19:58:40.796Z","closed_at":"2025-12-22T19:58:40.796Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjhkiuletid","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjhkium1nmk","title":"Analytics Query Builder and Types","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-22T19:47:51.289Z","updated_at":"2025-12-22T19:58:41.641Z","closed_at":"2025-12-22T19:58:41.641Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjhkiuletid","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjhkium6rpy","title":"Pre-built Analytics Queries (1-5)","status":"in_progress","priority":2,"issue_type":"task","created_at":"2025-12-22T19:47:51.294Z","updated_at":"2025-12-22T20:03:08.359Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjhkiuletid","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjhkiumaibf","title":"Pre-built Analytics Queries (6-10)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-22T19:47:51.298Z","updated_at":"2025-12-22T20:07:48.342Z","closed_at":"2025-12-22T20:07:48.342Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjhkiuletid","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjhkvabovqo","title":"Agent-facing Analytics Tools (MCP/Plugin Integration)","description":"Expose observability tools to agents via plugin tools, not just CLI.\n\n## Why This Matters\nAgents need to:\n1. **Debug swarm failures** - query why an epic failed without human intervention\n2. **Generate insights** - \"what strategies are failing?\" for learning loops\n3. **Self-diagnose** - when blocked, query recent events for context\n4. **Report to coordinator** - structured analytics in swarm mail\n\n## Tools to Add\n\n### `swarm_analytics` - Query pre-built analytics\n```typescript\nswarm_analytics({\n  query: \"failed-decompositions\" | \"strategy-success-rates\" | \"lock-contention\" | ...,\n  since?: string,  // \"7d\", \"24h\"\n  format?: \"json\" | \"summary\"  // summary = human-readable for context\n})\n```\n\n### `swarm_query` - Raw SQL for power users\n```typescript\nswarm_query({\n  sql: \"SELECT * FROM events WHERE type = 'task_blocked' LIMIT 5\",\n  format?: \"json\" | \"table\"\n})\n```\n\n### `swarm_diagnose` - Auto-diagnosis for current epic\n```typescript\nswarm_diagnose({\n  epic_id: string,\n  include?: [\"blockers\", \"conflicts\", \"slow_tasks\", \"errors\"]\n})\n// Returns structured diagnosis with suggestions\n```\n\n### `swarm_insights` - Generate learning insights\n```typescript\nswarm_insights({\n  scope: \"epic\" | \"project\" | \"all\",\n  epic_id?: string,\n  metrics: [\"success_rate\", \"duration\", \"conflicts\", \"retries\"]\n})\n// Returns insights suitable for semantic-memory storage\n```\n\n## Integration Points\n- Add to `packages/opencode-swarm-plugin/src/plugin.ts`\n- Use analytics module from swarm-mail\n- Context-safe output (truncate large results)\n- JSON output for agent consumption\n\n## TDD Requirements\n- Test each tool returns valid structured output\n- Test context limits (max rows, truncation)\n- Test error handling (invalid queries, missing epic)\n\n## Files\n- packages/opencode-swarm-plugin/src/observability-tools.ts (new)\n- packages/opencode-swarm-plugin/src/observability-tools.test.ts (new)\n- packages/opencode-swarm-plugin/src/plugin.ts (add tools)","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-22T19:57:31.524Z","updated_at":"2025-12-22T19:57:31.524Z","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjhkiuletid","title":"Observability Stack MVP: Error Enrichment + SQL CLI","description":"TDD-driven implementation of Phase 1 (structured error classes with context/suggestions, DEBUG env var filtering) and Phase 2 (swarm-db CLI with raw SQL and 10 pre-built analytics queries). Every feature starts with a failing test.\n\n## Knowledge Sources\n- Four Golden Signals (SRE): latency, traffic, errors, saturation → mapped to analytics queries\n- Agent Observability: agent-aware tracing with bead_id/epic_id correlation\n- Event Sourcing: SQL CLI as diagnostic view over existing 17 event types\n- TDD Lore: Kent Beck, Sandi Metz - red-green-refactor, characterization tests\n\n## Success Criteria\n- All error classes have toJSON() with rich context + suggestions\n- DEBUG=swarm:* filters log output by subsystem\n- `swarm-db query` executes raw SQL against libSQL\n- `swarm-db analytics` runs 10 pre-built queries with --format, --since, --until\n- 100% test coverage on new code (unit + integration)\n\n## Parent Epic\nopencode-swarm-monorepo-lf2p4u-mjhk4kkh975","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-12-22T19:47:51.266Z","updated_at":"2025-12-22T20:24:42.998Z","closed_at":"2025-12-22T20:24:42.998Z","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjfyo44apwt","title":"Add Haiku-Powered Compaction Analysis","description":"Wire liteModel into plugin template and use it for pre-analysis during compaction.\n\n1. Parameterize getPluginWrapper() to accept liteModel\n2. Update compaction hook to call `opencode run -m <liteModel>` for pre-analysis\n3. Use output.prompt to replace compaction prompt with pre-analyzed state\n\nThis enables smarter compaction that preserves swarm state for continuation.","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-12-21T16:48:19.162Z","updated_at":"2025-12-23T16:46:43.839Z","closed_at":"2025-12-23T16:46:43.839Z","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjithnuayc9","title":"LLM-Powered Compaction with output.prompt Replacement","description":"Leverage the new `output.prompt` API from OpenCode PR #5907 to completely replace the compaction prompt with an LLM-generated swarm-forward continuation prompt.\n\n## Key Features\n1. Use lite model (Haiku or user-configured) via `opencode run -m <liteModel>`\n2. Generate dynamic continuation prompt based on actual swarm state\n3. Progressive enhancement - gracefully degrade on older OpenCode versions\n4. Fallback to static context if LLM call fails\n\n## Design Decisions\n- Shell out to `opencode run` (no new dependencies)\n- Guard against missing `output.prompt` API\n- Fallback chain: LLM prompt → static context → detection fallback\n\n## Related\n- OpenCode PR: https://github.com/sst/opencode/pull/5907\n- Existing cell: opencode-swarm-monorepo-lf2p4u-mjfyo44apwt","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-12-23T16:46:38.578Z","updated_at":"2025-12-23T16:54:33.156Z","closed_at":"2025-12-23T16:54:33.156Z","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjithnuh0pv","title":"ADR: LLM-Powered Compaction Architecture","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-23T16:46:38.585Z","updated_at":"2025-12-23T16:50:34.232Z","closed_at":"2025-12-23T16:50:34.232Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjithnuayc9","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjithnujolm","title":"Implement LLM Compaction in plugin-wrapper-template.ts","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-23T16:46:38.587Z","updated_at":"2025-12-23T16:54:31.512Z","closed_at":"2025-12-23T16:54:31.512Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjithnuayc9","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjfzlbckh37","title":"Create Hive/Cell Visualizer","description":"Build a visualizer for hive cells inspired by https://github.com/Dicklesworthstone/beads_viewer and https://github.com/mantoni/beads-ui\n\n**ADR:** `.hive/analysis/hive-cell-visualizer.md`\n\n## Decision Summary (Updated 2025-12-23)\n\nBuild a **three-part visualizer** using modern stack:\n\n1. **CLI Query Tool** (`swarm viz`): Quick terminal-based status views\n2. **TanStack Start Web App** (`swarm viz --serve`): Real-time interactive visualization\n3. **Static HTML Export** (`swarm viz --export`): Self-contained snapshot for sharing\n\n## Key Architecture Decisions\n\n### TanStack Start + Durable Streams\n\n- **TanStack Start**: Type-safe routing, SSR + streaming, server functions, Vite-powered\n- **Durable Streams Protocol**: Electric's open protocol for real-time sync\n  - Offset-based resumability (refresh-safe, multi-device, multi-tab)\n  - Long-poll and SSE modes for live tailing\n  - CDN-friendly design for massive fan-out\n\n### Why Durable Streams over WebSocket?\n\n1. **Refresh-safe**: User refreshes → picks up exactly where they left off\n2. **Multi-tab**: Multiple tabs share stream without duplicating connections\n3. **Production-proven**: 1.5 years at Electric, millions of events/day\n\n## Implementation Phases\n\n1. **Phase 1**: Durable Streams adapter for swarm-mail events\n2. **Phase 2**: Data layer + CLI views (status table, tree, kanban)\n3. **Phase 3**: TanStack Start web app with live updates\n4. **Phase 4**: Static HTML export + plugin integration\n\n## Technical Stack\n\n- TypeScript/Bun\n- TanStack Start (React framework)\n- @durable-streams/client for browser subscription\n- force-graph for visualization\n- libSQL event store (existing swarm-mail)\n\n---\n\n## 🔗 Related: Logging Infrastructure\n\n**Cell:** `opencode-swarm-plugin--ys7z8-mjk6pwwn9nw`\n\nPino-based logging (`~/.config/swarm-tools/logs/`) feeds into the visualizer:\n- `swarm log` CLI for querying structured logs\n- Compaction hook as first instrumentation target\n- Logs panel in web UI showing real-time activity\n\n---\n\n## 🔮 Future Vision: Control Plane\n\n**Memory:** `cdcf917a-f473-4d2d-9bb5-63baa35baa3b`\n\nThe viewer evolves from read-only dashboard to **control plane**:\n\n1. **Dynamic Prompts** - Edit coordinator/worker prompts in UI, stored in libSQL\n2. **Compaction Tuning** - Adjust context priorities, token budgets, preservation rules\n3. **Skills Management** - Enable/disable, edit content, project-specific overrides\n4. **Learning Tuning** - Confidence decay rates, pattern maturity thresholds\n5. **A/B Testing** - Run prompt variants, measure outcomes\n\nThis transforms hardcoded TypeScript behavior into database-driven, user-tunable configuration.\n\n---\n\n## References\n\n- Durable Streams: https://github.com/durable-streams/durable-streams\n- beads-ui: https://github.com/mantoni/beads-ui\n- beads_viewer: https://github.com/Dicklesworthstone/beads_viewer\n- TanStack Start: https://tanstack.com/start","status":"in_progress","priority":2,"issue_type":"feature","created_at":"2025-12-21T17:14:08.180Z","updated_at":"2025-12-23T17:18:10.968Z","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjix9j65b49","title":"Create swarm/researcher agent template","status":"closed","priority":0,"issue_type":"task","created_at":"2025-12-23T18:32:17.741Z","updated_at":"2025-12-23T18:41:51.421Z","closed_at":"2025-12-23T18:41:51.421Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjix9j5ssyz","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjix9j6ych1","title":"Add researcher prompt template","status":"closed","priority":0,"issue_type":"task","created_at":"2025-12-23T18:32:17.770Z","updated_at":"2025-12-23T18:41:53.462Z","closed_at":"2025-12-23T18:41:53.462Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjix9j5ssyz","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjix9j730vx","title":"Implement tool discovery for researchers","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-23T18:32:17.775Z","updated_at":"2025-12-23T18:51:29.505Z","closed_at":"2025-12-23T18:51:29.505Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjix9j5ssyz","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjix9j77zkw","title":"Implement lockfile parsing for version detection","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-23T18:32:17.779Z","updated_at":"2025-12-23T19:04:42.600Z","closed_at":"2025-12-23T19:04:42.600Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjix9j5ssyz","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjix9j7bmjy","title":"Add research phase to swarm orchestration","status":"closed","priority":0,"issue_type":"task","created_at":"2025-12-23T18:32:17.783Z","updated_at":"2025-12-23T19:08:57.843Z","closed_at":"2025-12-23T19:08:57.843Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjix9j5ssyz","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjix9j7enle","title":"Update worker prompt with on-demand research capability","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-23T18:32:17.786Z","updated_at":"2025-12-23T18:56:42.420Z","closed_at":"2025-12-23T18:56:42.420Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjix9j5ssyz","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjix9j7ju52","title":"Add --check-upgrades flag support","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-23T18:32:17.791Z","updated_at":"2025-12-23T19:16:44.200Z","closed_at":"2025-12-23T19:16:44.200Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjix9j5ssyz","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjix9j7xo6h","title":"Write tests for research phase","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-23T18:32:17.805Z","updated_at":"2025-12-23T19:16:40.897Z","closed_at":"2025-12-23T19:16:40.897Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjix9j5ssyz","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjix9j5ssyz","title":"Add Research Phase to /swarm Command","description":"Add a pre-decomposition research phase to the /swarm command that spawns research workers to gather documentation and version information before task decomposition.\n\n## Key Features\n\n1. **swarm/researcher agent type** - New agent that:\n   - Dynamically discovers user's installed tools (MCP servers, skills)\n   - Reads lockfiles to get current package versions\n   - Fetches docs for installed versions using available tools\n   - Stores full findings in semantic-memory\n   - Broadcasts condensed summaries via swarm mail\n   - Uses user's configured worker model (mid-tier)\n\n2. **Pre-decomposition research phase** - Coordinator:\n   - Analyzes task + codebase to identify tech stack\n   - Spawns research workers with explicit tech list\n   - Waits for research to complete\n   - Injects findings into shared_context for all workers\n\n3. **On-demand research in workers** - Update worker prompts to:\n   - Enable spawning research subagents when hitting unknowns\n   - Query semantic memory for existing research first\n\n4. **--check-upgrades flag** - Optional comparison of current vs latest versions\n\n## Architecture\n\n```\nCoordinator receives task\n    ↓\nAnalyze task + codebase → identify tech stack\n    ↓\nSpawn swarm/researcher workers (parallel)\n    ↓\nResearchers: discover tools → read lockfiles → fetch docs → store + broadcast\n    ↓\nCoordinator: collect summaries → inject into shared_context\n    ↓\nNormal decomposition continues with enriched context\n```","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-12-23T18:32:17.728Z","updated_at":"2025-12-23T19:17:41.150Z","closed_at":"2025-12-23T19:17:41.150Z","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjfzm2qunwj","title":"Analyze agentic_coding_flywheel_setup for ideas","description":"Analyze https://github.com/Dicklesworthstone/agentic_coding_flywheel_setup for ideas to extract and improve our swarm system.\n\nLook for:\n- Workflow patterns\n- Agent coordination strategies\n- Learning/feedback loops\n- Tool integration patterns\n\n## Research Complete ✓\n\nWorker analyzed the repo and identified 5 key patterns to adopt:\n\n1. **Manifest-Driven Tool Generation** - YAML → TypeScript → tools (4 days)\n2. **Stable Phase IDs** - String IDs instead of array indices for subtasks (1 day)\n3. **Contract Validation** - Pre-flight checks before worker execution (2 days)\n4. **Doctor-Style Health Checks** - 3-tier with caching + timeouts (3 days)\n5. **Checksum-Verified Skills** - Security for external skill downloads (2 days)\n\n**Biggest gap:** No equivalent to `acfs_require_contract()` - workers can call swarm tools without proper initialization.\n\n**ADR:** `.hive/analysis/agentic-flywheel-analysis.md`","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-21T17:14:43.686Z","updated_at":"2025-12-24T15:43:42.614Z","closed_at":"2025-12-24T15:43:42.614Z","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjk6htl0c24","title":"Swarm coordinator should spawn research workers, not fetch files directly","description":"**Problem:** Coordinator is doing research grunt work (repo-crawl_file, fetching docs) instead of spawning a research worker to do it.\n\n**Root cause:** The swarm prompts don't enforce the coordinator/worker separation strongly enough. Coordinator prompt should:\n1. NEVER call repo-crawl_*, webfetch, or other research tools directly\n2. ALWAYS spawn a `swarm-researcher` or `explore` agent for information gathering\n3. Only synthesize results returned by workers\n\n**Current behavior:**\n- Coordinator calls `repo-crawl_file` 10+ times directly\n- Burns coordinator context on raw file contents\n- Doesn't leverage parallel research workers\n\n**Expected behavior:**\n```\nCoordinator:\n  1. swarm_spawn_subtask(type=\"research\", task=\"Analyze ACFS workflow patterns\")\n  2. swarm_spawn_subtask(type=\"research\", task=\"Analyze ACFS agent coordination\")\n  3. Wait for workers to return summaries\n  4. Synthesize into ADR\n```\n\n**Fix locations:**\n- `src/swarm-prompts.ts` - coordinator prompt needs explicit \"NEVER fetch directly\" rule\n- `src/swarm-orchestrate.ts` - research phase should spawn workers, not run inline\n- Consider adding a `swarm_spawn_researcher` convenience tool\n\n**Related:** Research phase was just added but it runs inline in coordinator context instead of spawning workers.","status":"open","priority":1,"issue_type":"bug","created_at":"2025-12-24T15:38:27.204Z","updated_at":"2025-12-24T15:38:27.204Z","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjk6mha6mi2","title":"Add observability to pre-compaction hook","description":"**Problem:** The pre-compaction hook does significant work (context analysis, memory extraction, pattern detection) but provides zero visibility into what it's doing or how well it's working.\n\n**Current state:**\n- Hook runs silently before context compaction\n- No logging of what patterns were detected\n- No metrics on extraction success/failure\n- No way to debug why certain learnings weren't captured\n- Can't analyze effectiveness over time\n\n**What we need:**\n\n1. **Structured logging** - What the hook analyzed, what it extracted, what it skipped\n2. **Metrics** - Success rates, extraction counts, timing data\n3. **Debug mode** - Verbose output showing decision process\n4. **Post-hoc analysis** - Queryable history of hook runs\n\n**Potential approaches:**\n- Emit events to swarm-mail event store (queryable, persistent)\n- Write to `.hive/compaction-log.jsonl` (simple, greppable)\n- Add `--verbose` flag to hook invocation\n- Dashboard/CLI command to analyze hook effectiveness\n\n**Files:**\n- `packages/opencode-swarm-plugin/src/compaction-hook.ts`\n- Possibly new: `src/compaction-observability.ts`\n\n**Success criteria:**\n- Can answer: \"What did the last 10 compaction runs extract?\"\n- Can answer: \"Why didn't this pattern get captured?\"\n- Can see timing breakdown (analysis vs extraction vs storage)","status":"open","priority":1,"issue_type":"feature","created_at":"2025-12-24T15:42:04.542Z","updated_at":"2025-12-24T15:42:04.542Z","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjk72toopj7","title":"Add PRAGMA busy_timeout to libSQL connection","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-24T15:54:47.112Z","updated_at":"2025-12-24T15:54:47.112Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjk72togddz","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjk72tor6jx","title":"Create Effect-based withSqliteRetry utility","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-24T15:54:47.115Z","updated_at":"2025-12-24T15:54:47.115Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjk72togddz","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjk6s5lg2g1","title":"Swarm tools need SQLite retry logic for SQLITE_BUSY errors","description":"**Problem:** `hive_sync` and other swarm tools fail with `SQLITE_BUSY: database is locked` instead of retrying.\n\n**Root cause:** Multiple agents/processes accessing the same libSQL database concurrently. SQLite handles this with WAL mode and busy timeouts, but we're not configuring them properly or implementing retry logic.\n\n**Current behavior:**\n```\nhive_sync() → SQLITE_BUSY → immediate failure → user has to retry manually\n```\n\n**Expected behavior:**\n```\nhive_sync() → SQLITE_BUSY → exponential backoff retry (3 attempts) → success or actionable error\n```\n\n**Affected tools:**\n- `hive_sync`, `hive_create`, `hive_update`, `hive_close`\n- `swarmmail_send`, `swarmmail_reserve`, `swarmmail_release`\n- `semantic-memory_store`, `semantic-memory_find`\n- Any tool that writes to libSQL\n\n## Existing Patterns in Codebase\n\nWe already have retry logic in Effect-based code:\n\n1. **`streams/effect/lock.ts`** - Exponential backoff for lock contention:\n```typescript\nconst retrySchedule = Schedule.exponential(baseDelayMs).pipe(\n  Schedule.intersect(Schedule.recurs(maxRetries))\n);\nEffect.retry(retrySchedule)\n```\n\n2. **`memory/ollama.ts`** - Retry for Ollama API calls\n\n3. **`streams/store.ts`** - Idempotency handling for network retries\n\n## Implementation Plan\n\n### Option 1: SQLite busy_timeout (Simplest)\n\nConfigure at connection level - SQLite will automatically retry internally:\n\n```typescript\n// In libsql.ts createLibSQLAdapter()\nconst client = createClient({\n  url: config.url,\n  authToken: config.authToken,\n  // SQLite busy_timeout in milliseconds\n  // Will retry internally for up to 5 seconds\n  intMode: \"number\",\n});\n\n// After connection, set busy_timeout\nawait client.execute(\"PRAGMA busy_timeout = 5000\");\n```\n\n### Option 2: Application-level retry wrapper\n\nWrap all DB operations with retry logic:\n\n```typescript\n// New: src/db/retry.ts\nexport async function withRetry<T>(\n  operation: () => Promise<T>,\n  options: {\n    maxRetries?: number;\n    baseDelayMs?: number;\n    retryableErrors?: string[];\n  } = {}\n): Promise<T> {\n  const { maxRetries = 3, baseDelayMs = 100, retryableErrors = [\"SQLITE_BUSY\"] } = options;\n  \n  for (let attempt = 0; attempt <= maxRetries; attempt++) {\n    try {\n      return await operation();\n    } catch (error) {\n      const isRetryable = retryableErrors.some(e => \n        error instanceof Error && error.message.includes(e)\n      );\n      \n      if (!isRetryable || attempt === maxRetries) {\n        throw error;\n      }\n      \n      const delay = baseDelayMs * Math.pow(2, attempt);\n      await new Promise(resolve => setTimeout(resolve, delay));\n    }\n  }\n  throw new Error(\"Unreachable\");\n}\n```\n\n### Option 3: Effect-based retry (Consistent with existing code)\n\nUse Effect's retry combinators like we do in lock.ts:\n\n```typescript\nconst retrySchedule = Schedule.exponential(\"100 millis\").pipe(\n  Schedule.intersect(Schedule.recurs(3)),\n  Schedule.whileInput((error: Error) => \n    error.message.includes(\"SQLITE_BUSY\")\n  )\n);\n\nconst safeQuery = <T>(query: Effect.Effect<T, Error>) =>\n  query.pipe(Effect.retry(retrySchedule));\n```\n\n## Reference: Release It! Patterns\n\nFrom pdf-brain concepts:\n- **Timeout Handling** - Set time limits on operations at integration points\n- **Circuit Breaker Pattern** - Break connections when downstream unavailable\n- **Bulkhead Pattern** - Isolate resources to prevent cascade failures\n\nKey insight: \"Integration points are the number one killer of systems\" - every database call is an integration point that needs protection.\n\n## Recommendation\n\n1. **Immediate fix:** Add `PRAGMA busy_timeout = 5000` to libsql.ts (5 min effort)\n2. **Better fix:** Add `withRetry()` wrapper for all adapter methods (2 hours)\n3. **Best fix:** Migrate to Effect-based retry like lock.ts (1 day)\n\n**Files:**\n- `packages/swarm-mail/src/libsql.ts` - Add busy_timeout PRAGMA\n- `packages/swarm-mail/src/adapter.ts` - Wrap operations with retry\n- Possibly new: `src/db/retry.ts` - Reusable retry utility","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-24T15:46:29.332Z","updated_at":"2025-12-24T16:12:17.663Z","closed_at":"2025-12-24T16:12:17.663Z","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjk72togddz","title":"SQLite Retry Logic - PRAGMA + Effect-based","description":"Implement SQLite retry logic for SQLITE_BUSY errors to handle multi-agent concurrent database access.\n\n## Approach\n1. PRAGMA busy_timeout = 5000 (SQLite-level retry, 5 seconds)\n2. Effect-based retry wrapper using Schedule.exponential() pattern from lock.ts\n3. Apply retry to adapter write operations\n\n## Existing Patterns\n- `streams/effect/lock.ts`: Schedule.exponential(baseDelayMs).pipe(Schedule.compose(Schedule.recurs(maxRetries)))\n- `memory/ollama.ts`: Effect retry for API calls\n\n## Success Criteria\n- PRAGMA busy_timeout set on all new connections\n- Effect-based retry wrapper handles SQLITE_BUSY with exponential backoff\n- Adapter write operations wrapped with retry\n- Tests verify retry behavior\n\n## Related Cell\nCloses: opencode-swarm-monorepo-lf2p4u-mjk6s5lg2g1","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-12-24T15:54:47.104Z","updated_at":"2025-12-24T16:12:15.816Z","closed_at":"2025-12-24T16:12:15.816Z","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjk72touuqg","title":"Apply retry wrapper to adapter write operations","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-24T15:54:47.118Z","updated_at":"2025-12-24T16:12:12.960Z","closed_at":"2025-12-24T16:12:12.960Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjk72togddz","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjk7ztm5jmu","title":"Research: Worker retry loop for review feedback","description":"## Problem\n\n`swarm_review_feedback` sends messages to dead workers. Workers are ephemeral Task subagents - they complete and return, then they're gone. The feedback message goes to a mailbox nobody reads.\n\n## Current Flow (Broken)\n\n```\nCoordinator spawns Worker → Worker works → Worker returns result\n                                                    ↓\n                                          Coordinator reviews diff\n                                                    ↓\n                                          swarm_review_feedback(needs_changes)\n                                                    ↓\n                                          Message sent to dead worker 💀\n```\n\n## What Should Happen\n\nWhen `swarm_review_feedback` returns `needs_changes`, the **coordinator** should:\n1. Read the issues from the response\n2. Spawn a NEW worker with: original task + issues + \"fix these\"\n3. Repeat until approved or 3 failures\n\nThe retry loop belongs in the **coordinator**, not the worker.\n\n## Research Questions\n\n1. **Session continuity**: Can we use `session_id` in Task tool to continue a worker session?\n2. **Prompt injection**: Should feedback be injected into a new worker prompt?\n3. **State preservation**: How do we pass \"attempt 2 of 3\" context to new worker?\n4. **Diff context**: Should new worker see the diff of what previous worker did?\n\n## Options to Explore\n\n### Option A: Coordinator-driven retry loop\n```\nwhile (attempts < 3) {\n  result = await Task(worker_prompt + previous_feedback)\n  review = swarm_review(...)\n  if (approved) break\n  feedback = swarm_review_feedback(needs_changes, issues)\n  attempts++\n}\n```\n\n### Option B: Session continuation\n```\nresult = await Task(..., session_id=\"worker-123\")\n// If needs_changes:\nresult = await Task(\"Fix these issues: ...\", session_id=\"worker-123\")  // Same session\n```\n\n### Option C: Persistent worker agents\n- Workers don't return until approved\n- Workers check inbox periodically\n- Coordinator sends feedback, worker reads and retries\n- More complex, requires worker polling loop\n\n## Files to Investigate\n\n- `src/swarm-review.ts` - current feedback mechanism\n- `src/swarm-prompts.ts` - worker prompt generation\n- `src/swarm-orchestrate.ts` - coordinator workflow\n- OpenCode Task tool docs - session_id behavior\n\n## Success Criteria\n\n- Design doc with recommended approach\n- Clear implementation plan\n- Addresses: state preservation, attempt tracking, feedback injection\n- Considers: context efficiency, error recovery, learning signals","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-24T16:20:26.669Z","updated_at":"2025-12-24T16:20:26.669Z","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjk8ee75zkc","title":"Fix Review Loop - Coordinator-Driven Retry","description":"## Problem\n\n`swarm_review_feedback` sends messages to dead workers. Workers are ephemeral Task subagents - they complete and return, then they're gone. The feedback message goes to a mailbox nobody reads.\n\n## Constraint (OpenCode Reality)\n\nWorkers are **fire-and-forget**:\n- Spin up, work, output, die\n- Cannot receive messages after completion\n- Coordinator is locked while worker runs\n- True async/background agents are a future feature (see OpenCode #5887)\n\n## Solution: Coordinator-Driven Retry\n\nWhen `swarm_review_feedback` returns `needs_changes`:\n1. Coordinator reads the issues from response\n2. Coordinator spawns NEW worker with: original task + issues + diff\n3. New worker fixes the issues\n4. Repeat until approved or 3 failures\n\nThe retry loop lives in the **coordinator**, not the worker.\n\n## Key Changes\n\n1. **New tool: `swarm_spawn_retry`** - Generates retry prompt with context\n2. **Update `swarm_review_feedback`** - Return retry context, don't message dead workers\n3. **Update coordinator prompts** - Document retry loop pattern\n4. **ADR** - Document architecture and future considerations\n\n## Success Criteria\n\n- Coordinator can retry failed workers with full context\n- No messages sent to dead workers\n- 3-strike rule actually works\n- Clear documentation of the pattern\n\n## References\n\n- OpenCode Issue #5887: True Async/Background Sub-Agent Delegation (future)\n- Semantic Memory: 2d1dcfa7 (Mandatory Coordinator Review Loop Pattern)","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-12-24T16:31:46.529Z","updated_at":"2025-12-24T16:33:24.055Z","closed_at":"2025-12-24T16:33:24.055Z","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjk8ee7ezb4","title":"Create swarm_spawn_retry tool for retry prompts","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-24T16:31:46.538Z","updated_at":"2025-12-24T16:33:24.609Z","closed_at":"2025-12-24T16:33:24.609Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjk8ee75zkc","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjk8ee7g7u0","title":"Update swarm_review_feedback to return retry context","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-24T16:31:46.540Z","updated_at":"2025-12-24T16:33:25.499Z","closed_at":"2025-12-24T16:33:25.499Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjk8ee75zkc","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjk8ee7iqti","title":"Update coordinator post_completion_instructions with retry loop","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-24T16:31:46.542Z","updated_at":"2025-12-24T16:33:26.706Z","closed_at":"2025-12-24T16:33:26.706Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjk8ee75zkc","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjk8ee7kx2b","title":"Update bin/swarm.ts Phase 7 retry documentation","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-24T16:31:46.544Z","updated_at":"2025-12-24T16:33:27.880Z","closed_at":"2025-12-24T16:33:27.880Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjk8ee75zkc","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjk8ee7nh7b","title":"Create ADR: Coordinator-Driven Retry Architecture","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-24T16:31:46.547Z","updated_at":"2025-12-24T16:33:28.808Z","closed_at":"2025-12-24T16:33:28.808Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjk8ee75zkc","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjk8h0cnppf","title":"Fix Review Loop - Coordinator-Driven Retry","description":"Workers are fire-and-forget. swarm_review_feedback sends messages to dead workers. Fix by making coordinator drive the retry loop - spawn new workers with feedback context instead of messaging dead ones.\n\n## Constraint (OpenCode Reality)\n\nWorkers are ephemeral Task subagents:\n- Spin up, work, output, die\n- Cannot receive messages after completion\n- Coordinator is locked while worker runs\n- True async/background agents are future (OpenCode #5887)\n\n## Solution\n\nWhen `swarm_review_feedback` returns `needs_changes`:\n1. Coordinator calls `swarm_spawn_retry()` to generate retry prompt\n2. Coordinator spawns NEW worker with Task() using that prompt\n3. New worker has: original task + issues + diff context\n4. Repeat until approved or 3 failures\n\n## Validated Decomposition\n\nStrategy: risk-based (TDD first, isolate changes)\nTotal complexity: 11 | Files: 6 | Subtasks: 4","status":"open","priority":1,"issue_type":"epic","created_at":"2025-12-24T16:33:48.551Z","updated_at":"2025-12-24T16:33:48.551Z","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjk8h0d8rzl","title":"Update bin/swarm.ts Phase 7 retry documentation","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-24T16:33:48.572Z","updated_at":"2025-12-24T16:33:48.572Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjk8h0cnppf","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjk8h0da1zn","title":"Create ADR: Coordinator-Driven Retry Architecture","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-24T16:33:48.574Z","updated_at":"2025-12-24T16:33:48.574Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjk8h0cnppf","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjk8h0cypll","title":"Add swarm_spawn_retry tool with tests (TDD)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-24T16:33:48.562Z","updated_at":"2025-12-24T16:45:13.589Z","closed_at":"2025-12-24T16:45:13.589Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjk8h0cnppf","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjk8h0d48zt","title":"Update swarm_review_feedback to return retry context","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-24T16:33:48.568Z","updated_at":"2025-12-24T16:52:49.819Z","closed_at":"2025-12-24T16:52:49.819Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjk8h0cnppf","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjk8iblv9ej","title":"Enforce mandatory decomposition validation in coordinator prompt","description":"## Problem\n\nCoordinator skipped `swarm_plan_prompt` → `swarm_validate_decomposition` → `hive_create_epic` flow and went straight to ASCII art planning + direct epic creation. This bypassed:\n- File conflict detection\n- Dependency validation  \n- Strategy selection\n- Structured schema enforcement\n\n## Root Cause\n\nThe coordinator prompt in `bin/swarm.ts` Phase 3 mentions the tools but doesn't make them **mandatory**. Nothing prevents calling `hive_create_epic` directly.\n\n## Fix\n\nUpdate `bin/swarm.ts` Phase 3 (Decompose) to:\n1. Make the flow explicit and non-negotiable\n2. Add \"DO NOT skip these steps\" warning like we have for other phases\n3. Show the exact sequence with tool calls\n4. Explain WHY: validation catches file conflicts before workers get stuck\n\n## Example Update\n\n```markdown\n### Phase 3: Decompose (MANDATORY - DO NOT SKIP)\n\n**⚠️ You MUST use structured decomposition. Do NOT create epics from ASCII art or mental planning.**\n\n1. Generate decomposition prompt:\n   `swarm_plan_prompt(task=\"<task>\", context=\"<knowledge>\", max_subtasks=N)`\n\n2. Respond with CellTree JSON matching the schema\n\n3. Validate before creating cells:\n   `swarm_validate_decomposition(response=\"<your JSON>\")`\n   \n   This catches:\n   - File conflicts (same file in multiple subtasks)\n   - Invalid dependencies\n   - Schema violations\n\n4. ONLY after validation passes:\n   `hive_create_epic(epic_title, subtasks from validated response)`\n\n**Why this matters:** File conflicts cause workers to block on reservations. Validation catches this BEFORE spawning workers.\n```\n\n## Files\n\n- packages/opencode-swarm-plugin/bin/swarm.ts (Phase 3 section)","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-24T16:34:49.795Z","updated_at":"2025-12-24T16:34:49.795Z","parent_id":"opencode-swarm-monorepo-lf2p4u-mjk8h0cnppf","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjk8tk7jn11","title":"Research: Coordinator prompt iteration with evals + o11y feedback loop","description":"## Problem\n\nThe coordinator prompt in `bin/swarm.ts` is ~500 lines of instructions that we iterate on by feel. When something goes wrong (like me skipping decomposition validation), we add more warnings. But we have no way to:\n\n1. **Measure** if the prompt changes actually work\n2. **A/B test** different prompt versions\n3. **Correlate** prompt changes with swarm outcomes\n4. **Identify** which instructions are ignored vs followed\n\n## What We Have Now\n\n- **Observability tools** (just committed): analytics queries, event store, pre-built queries\n- **Learning system**: pattern maturity, confidence decay, outcome tracking\n- **Swarm events**: task_started, task_completed, task_blocked, review_approved, review_rejected\n\n## What We Need\n\n### Option A: Lightweight - Prompt Versioning + Analytics\n\n1. Version the coordinator prompt (hash or semver)\n2. Tag swarm events with prompt version\n3. Query: \"success rate by prompt version\"\n4. Manual iteration based on data\n\n### Option B: Medium - Evalite Integration\n\nWe have `evals/` directory with evalite setup. Could:\n1. Create coordinator prompt evals (given task, does it decompose correctly?)\n2. Test prompt variants offline before deploying\n3. Score: file conflicts detected, validation used, retry loop followed\n\n### Option C: Full - LLM-as-Judge Continuous Eval\n\n1. After each swarm completes, run eval on coordinator behavior\n2. LLM judges: \"Did coordinator follow the prompt?\"\n3. Auto-flag prompt sections that are consistently ignored\n4. Suggest prompt improvements\n\n## Research Questions\n\n1. What's the minimum viable eval for coordinator prompts?\n2. Can we use our existing o11y data to measure prompt effectiveness?\n3. How do we handle the meta-problem (prompt for evaluating prompts)?\n4. What does evalite need to test coordinator behavior specifically?\n\n## Related\n\n- `.hive/analysis/observability-*.md` - ADRs on o11y\n- `evals/` directory - existing evalite setup\n- `swarm-decomposition.eval.ts` - existing decomposition eval\n- OpenCode issue #5887 - async agents (future capability)\n\n## Deliverables\n\n1. Analysis of options A/B/C with effort estimates\n2. Recommendation for MVP approach\n3. If Option B: spec for coordinator prompt evals\n4. Integration plan with existing o11y tools","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-24T16:43:34.159Z","updated_at":"2025-12-24T16:43:34.159Z","dependencies":[],"labels":[],"comments":[]}
{"id":"opencode-swarm-monorepo-lf2p4u-mjk941x3gqy","title":"BUG: Coordinator does work directly after compaction instead of spawning workers","description":"## Critical Bug\n\n**Symptom:** After context compaction, the coordinator starts doing work directly instead of spawning worker agents. This breaks the entire swarm coordination model.\n\n**Root Cause Hypothesis:** \nWhen compaction happens mid-swarm, the coordinator loses:\n1. Its identity as \"coordinator\" (role context)\n2. The instruction to spawn workers via Task()\n3. The swarm state (which workers are active, what's been done)\n\nThe compacted context doesn't preserve the critical \"I am a COORDINATOR, I spawn workers, I don't do work\" instruction.\n\n**Evidence:**\n- Worker was spawned for subtask 2 (swarm_review_feedback retry context)\n- Worker completed successfully\n- But coordinator never reviewed the work or spawned next worker\n- Instead, coordinator context was lost and it started acting like a general agent\n\n**Current compaction hook gap:**\nThe hook injects generic \"you are a coordinator\" context but doesn't include:\n1. The SPECIFIC epic ID being coordinated\n2. Which subtasks are done/pending/in_progress  \n3. The original task description\n4. Which workers were spawned\n\nThe agent wakes up knowing it's a coordinator but not WHAT it's coordinating.\n\n**Next steps:**\n1. Set up o11y for compaction - capture what context exists before/after\n2. Create eval for coordinator resumption after compaction\n3. Analyze compaction logs to understand failure mode\n4. Fix compaction hook to include actual swarm state\n\n**Files:**\n- packages/opencode-swarm-plugin/src/compaction-hook.ts\n- packages/opencode-swarm-plugin/src/compaction-hook.test.ts\n\n**Failing tests added** (TDD red phase) - 3 tests expecting specific epic ID, subtask status, and project path in compaction context.","status":"open","priority":0,"issue_type":"bug","created_at":"2025-12-24T16:51:43.671Z","updated_at":"2025-12-24T16:55:03.185Z","dependencies":[],"labels":[],"comments":[]}
