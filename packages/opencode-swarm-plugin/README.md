# opencode-swarm-plugin

**Multi-agent swarm coordination for OpenCode - break tasks into parallel subtasks, spawn worker agents, learn from outcomes.**

**ğŸŒ Website:** [swarmtools.ai](https://swarmtools.ai)  
**ğŸ“š Full Documentation:** [swarmtools.ai/docs](https://swarmtools.ai/docs)

[![Eval Gate](https://github.com/joelhooks/opencode-swarm-plugin/actions/workflows/eval-gate.yml/badge.svg)](https://github.com/joelhooks/opencode-swarm-plugin/actions/workflows/eval-gate.yml)

```
 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—    â–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ•—
 â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•‘    â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ•‘
 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘ â–ˆâ•— â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ•‘
 â•šâ•â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘
 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘ â•šâ•â• â–ˆâ–ˆâ•‘
 â•šâ•â•â•â•â•â•â• â•šâ•â•â•â•šâ•â•â• â•šâ•â•  â•šâ•â•â•šâ•â•  â•šâ•â•â•šâ•â•     â•šâ•â•
```

## Quickstart (<2 minutes)

### 1. Install

```bash
npm install -g opencode-swarm-plugin@latest
swarm setup
```

### 2. Initialize in Your Project

```bash
cd your-project
swarm init
```

### 3. Run Your First Swarm

```bash
# Inside OpenCode
/swarm "Add user authentication with OAuth"
```

**What happens:**
- Task decomposed into parallel subtasks (coordinator queries past similar tasks)
- Worker agents spawn with file reservations
- Progress tracked with auto-checkpoints at 25/50/75%
- Completion runs bug scans, releases file locks, records learnings

Done. You're swarming.

---

## How Swarms Get Smarter Over Time

Swarms learn from outcomes. Every completed subtask records what worked and what failed - then injects that wisdom into future prompts.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        SWARM LEARNING LOOP                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚   â”‚  TASK    â”‚â”€â”€â”€â–¶â”‚ DECOMPOSEâ”‚â”€â”€â”€â–¶â”‚  EXECUTE â”‚â”€â”€â”€â–¶â”‚ COMPLETE â”‚         â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚        â–²               â”‚               â”‚               â”‚                â”‚
â”‚        â”‚               â–¼               â–¼               â–¼                â”‚
â”‚        â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚        â”‚         â”‚           EVENT STORE                   â”‚            â”‚
â”‚        â”‚         â”‚  subtask_outcome, eval_finalized, ...   â”‚            â”‚
â”‚        â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚        â”‚                           â”‚                                    â”‚
â”‚        â”‚                           â–¼                                    â”‚
â”‚        â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚        â”‚         â”‚         INSIGHTS LAYER                  â”‚            â”‚
â”‚        â”‚         â”‚  Strategy | File | Pattern insights     â”‚            â”‚
â”‚        â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚        â”‚                           â”‚                                    â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚
â”‚                  (injected into next decomposition)                     â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### The Insights Layer

**swarm-insights** (`src/swarm-insights.ts`) is the data aggregation layer that queries historical outcomes and semantic memory to provide context-efficient summaries for coordinator and worker agents.

**Three insight types:**

| Type | What It Tracks | Used By |
|------|----------------|---------|
| **StrategyInsight** | Success rates by decomposition strategy (file-based, feature-based, risk-based) | Coordinators |
| **FileInsight** | File-specific failure patterns and gotchas from past subtasks | Workers |
| **PatternInsight** | Common failure patterns across all subtasks (type errors, timeouts, conflicts) | Coordinators |

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         DATA FLOW                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   Event Store   â”‚     â”‚ Semantic Memory â”‚     â”‚  Anti-Patterns  â”‚   â”‚
â”‚  â”‚  (libSQL)       â”‚     â”‚  (Ollama/FTS)   â”‚     â”‚  (Registry)     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚           â”‚                       â”‚                       â”‚            â”‚
â”‚           â–¼                       â–¼                       â–¼            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    INSIGHTS AGGREGATION                         â”‚   â”‚
â”‚  â”‚                                                                 â”‚   â”‚
â”‚  â”‚  getStrategyInsights()  getFileInsights()  getPatternInsights() â”‚   â”‚
â”‚  â”‚         â”‚                      â”‚                    â”‚           â”‚   â”‚
â”‚  â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚   â”‚
â”‚  â”‚                                â–¼                                â”‚   â”‚
â”‚  â”‚                    formatInsightsForPrompt()                    â”‚   â”‚
â”‚  â”‚                    (token-budgeted output)                      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                   â”‚                                    â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚           â–¼                       â–¼                       â–¼            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   Coordinator   â”‚     â”‚     Worker      â”‚     â”‚     Worker      â”‚   â”‚
â”‚  â”‚   (strategy +   â”‚     â”‚  (file-specific â”‚     â”‚  (file-specific â”‚   â”‚
â”‚  â”‚    patterns)    â”‚     â”‚    gotchas)     â”‚     â”‚    gotchas)     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### API Reference

**For coordinators** (strategy selection):
```typescript
import { getStrategyInsights, getPatternInsights, formatInsightsForPrompt } from "opencode-swarm-plugin";

const strategies = await getStrategyInsights(swarmMail, task);
// Returns: [{ strategy: "file-based", successRate: 85.5, totalAttempts: 12, recommendation: "..." }]

const patterns = await getPatternInsights(swarmMail);
// Returns: [{ pattern: "type_error", frequency: 5, recommendation: "Add type annotations" }]

const summary = formatInsightsForPrompt({ strategies, patterns }, { maxTokens: 500 });
// Injected into decomposition prompt
```

**For workers** (file-specific context):
```typescript
import { getFileInsights, formatInsightsForPrompt } from "opencode-swarm-plugin";

const fileInsights = await getFileInsights(swarmMail, ["src/auth.ts", "src/db.ts"]);
// Returns: [{ file: "src/auth.ts", failureCount: 3, lastFailure: "2025-12-20T...", gotchas: [...] }]

const summary = formatInsightsForPrompt({ files: fileInsights }, { maxTokens: 300 });
// Injected into worker prompt
```

**Caching** (5-minute TTL):
```typescript
import { getCachedInsights, clearInsightsCache } from "opencode-swarm-plugin";

const insights = await getCachedInsights(swarmMail, "strategies:auth-task", async () => ({
  strategies: await getStrategyInsights(swarmMail, "add auth"),
}));

clearInsightsCache(); // Force fresh computation
```

### Token Budgets

| Agent Type | Max Tokens | What's Included |
|------------|------------|-----------------|
| Coordinator | 500 | Top 3 strategies + top 3 patterns |
| Worker | 300 | Top 5 files with gotchas |

### Recommendation Thresholds

Strategy success rates map to recommendations:

| Success Rate | Recommendation |
|--------------|----------------|
| â‰¥80% | "performing well" |
| 60-79% | "moderate - monitor for issues" |
| 40-59% | "low success - consider alternatives" |
| <40% | "AVOID - high failure rate" |

### Data Sources

| Source | What It Provides | Query Pattern |
|--------|------------------|---------------|
| Event Store | `subtask_outcome` events with strategy, success, files_touched, error_type | SQL aggregation |
| Semantic Memory | File-specific learnings from past debugging | Semantic search (TODO) |
| Anti-Pattern Registry | Patterns with >60% failure rate | Direct lookup |

**See [swarmtools.ai/docs/insights](https://swarmtools.ai/docs) for full details.**

---

## Optional But Recommended

### Semantic Memory (for pattern learning)

```bash
brew install ollama
ollama serve &
ollama pull mxbai-embed-large
```

Without Ollama, memory falls back to full-text search (still works, just less semantic).

### Historical Context (CASS)

Queries past AI sessions for similar decompositions:

```bash
git clone https://github.com/Dicklesworthstone/coding_agent_session_search
cd coding_agent_session_search
pip install -e .
cass index  # Run periodically to index new sessions
```

### Bug Scanning (UBS)

Auto-runs on subtask completion:

```bash
git clone https://github.com/Dicklesworthstone/ultimate_bug_scanner
cd ultimate_bug_scanner
pip install -e .
```

Check status: `swarm doctor`

---

## Core Concepts

### The Hive ğŸ

Work items (cells) stored in `.hive/` and synced to git. Each cell is a unit of work - think GitHub issue but local-first.

**Cell IDs:** Project-prefixed for clarity (e.g., `swarm-mail-lf2p4u-abc123` not generic `bd-xxx`)

### The Swarm

Parallel agents coordinated via **Swarm Mail** (message passing + file reservations). Coordinator spawns workers â†’ workers reserve files â†’ do work â†’ report progress â†’ complete with verification.

### Learning

- **Pattern maturity** tracks what decomposition strategies work
- **Confidence decay** fades unreliable patterns (90-day half-life)
- **Anti-pattern inversion** auto-marks failing approaches to avoid
- **Outcome tracking** learns from speed, errors, retries

### Checkpoint & Recovery

Auto-saves progress at milestones. Survives context death or crashes. Data stored in embedded libSQL (no external DB needed).

**When checkpoints happen:**
- Auto at 25%, 50%, 75% progress
- Before risky operations (via `swarm_checkpoint`)
- On errors (captures error context for recovery)

**Recovery:** `swarm_recover(project_key, epic_id)` returns full context to resume work.

---

## Tools Reference

### Hive (Work Item Tracking)

| Tool               | Purpose                               |
| ------------------ | ------------------------------------- |
| `hive_create`      | Create cell with type-safe validation |
| `hive_create_epic` | Atomic epic + subtasks creation       |
| `hive_query`       | Query with filters                    |
| `hive_update`      | Update status/description/priority    |
| `hive_close`       | Close with reason                     |
| `hive_start`       | Mark in-progress                      |
| `hive_ready`       | Get next unblocked cell               |
| `hive_sync`        | Sync to git                           |

> **Migration Note:** `beads_*` tools still work but show deprecation warnings. Update to `hive_*` tools.

### Swarm Mail (Agent Coordination)

| Tool                     | Purpose                          |
| ------------------------ | -------------------------------- |
| `swarmmail_init`         | Initialize session               |
| `swarmmail_send`         | Send message to agents           |
| `swarmmail_inbox`        | Fetch inbox (context-safe)       |
| `swarmmail_read_message` | Fetch one message body           |
| `swarmmail_reserve`      | Reserve files for exclusive edit |
| `swarmmail_release`      | Release reservations             |

### Swarm Orchestration

| Tool                           | Purpose                                         |
| ------------------------------ | ----------------------------------------------- |
| `swarm_select_strategy`        | Analyze task, recommend strategy                |
| `swarm_decompose`              | Generate decomposition prompt (queries CASS)    |
| `swarm_validate_decomposition` | Validate response, detect conflicts             |
| `swarm_subtask_prompt`         | Generate worker agent prompt                    |
| `swarm_status`                 | Get swarm progress by epic ID                   |
| `swarm_progress`               | Report subtask progress                         |
| `swarm_complete`               | Complete subtask (releases reservations)        |
| `swarm_checkpoint`             | Save progress snapshot (auto at 25/50/75%)      |
| `swarm_recover`                | Resume from checkpoint                          |
| `swarm_review`                 | Generate review prompt for coordinator          |
| `swarm_review_feedback`        | Send approval/rejection to worker (3-strike)    |

### Skills (Knowledge Injection)

| Tool            | Purpose                 |
| --------------- | ----------------------- |
| `skills_list`   | List available skills   |
| `skills_use`    | Load skill into context |
| `skills_read`   | Read skill content      |
| `skills_create` | Create new skill        |

**Bundled skills:**
- **testing-patterns** - 25 dependency-breaking techniques, characterization tests
- **swarm-coordination** - Multi-agent decomposition, file reservations
- **cli-builder** - Argument parsing, help text, subcommands
- **system-design** - Architecture decisions, module boundaries
- **learning-systems** - Confidence decay, pattern maturity
- **skill-creator** - Meta-skill for creating new skills

---

## What's New in v0.33

- **Pino logging infrastructure** - Structured JSON logs with daily rotation to `~/.config/swarm-tools/logs/`
- **Compaction hook instrumented** - 14 log points across all phases (START, GATHER, RENDER, DECIDE, COMPLETE)
- **`swarm log` CLI** - Query/tail logs with module, level, and time filters
- **Analytics queries** - 5 pre-built queries based on Four Golden Signals (latency, traffic, errors, saturation, conflicts)

### v0.32

- **libSQL storage** (embedded SQLite) replaced PGLite - no external DB needed
- **95% integration test coverage** - checkpoint/recovery proven with 9 tests
- **Coordinator review gate** - `swarm_review` + `swarm_review_feedback` with 3-strike rule
- **Smart ID resolution** - partial hashes work like git (`mjhgw0g` matches `opencode-swarm-monorepo-lf2p4u-mjhgw0ggt00`)
- **Auto-sync at key events** - no more forgotten `hive_sync` calls
- **Project-prefixed cell IDs** - `swarm-mail-xxx` instead of generic `bd-xxx`

---

## Architecture

Built on [swarm-mail](../swarm-mail) event sourcing primitives. Data stored in libSQL (embedded SQLite).

```
src/
â”œâ”€â”€ hive.ts                # Work item tracking integration
â”œâ”€â”€ swarm-mail.ts          # Agent coordination tools
â”œâ”€â”€ swarm-orchestrate.ts   # Coordinator logic (spawns workers)
â”œâ”€â”€ swarm-decompose.ts     # Task decomposition strategies
â”œâ”€â”€ swarm-insights.ts      # Historical insights aggregation (strategy/file/pattern)
â”œâ”€â”€ swarm-review.ts        # Review gate for completed work
â”œâ”€â”€ skills.ts              # Knowledge injection system
â”œâ”€â”€ learning.ts            # Pattern maturity, outcomes
â”œâ”€â”€ anti-patterns.ts       # Anti-pattern detection
â”œâ”€â”€ structured.ts          # JSON parsing utilities
â””â”€â”€ schemas/               # Zod validation schemas
```

---

## Development

```bash
# From monorepo root
bun turbo build --filter=opencode-swarm-plugin
bun turbo test --filter=opencode-swarm-plugin
bun turbo typecheck --filter=opencode-swarm-plugin

# Or from this directory
bun run build
bun test
bun run typecheck
```

### Evaluation Pipeline

Test decomposition quality and coordinator discipline with **Evalite** (TypeScript-native eval framework):

```bash
# Run all evals
bun run eval:run

# Run specific suites
bun run eval:decomposition    # Task decomposition quality
bun run eval:coordinator      # Coordinator protocol compliance
bun run eval:compaction       # Compaction prompt quality

# Check eval status (progressive gates)
swarm eval status [eval-name]

# View history with trends
swarm eval history
```

**Progressive Gates:**

```
Phase             Runs    Gate Behavior
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Bootstrap         <10     âœ… Always pass (collect data)
Stabilization     10-50   âš ï¸  Warn on >10% regression
Production        >50     âŒ Fail on >5% regression
```

**What gets evaluated:**

| Eval Suite            | Measures                                                      | Data Source                                      |
| --------------------- | ------------------------------------------------------------- | ------------------------------------------------ |
| `swarm-decomposition` | Subtask independence, complexity balance, coverage, clarity   | Fixtures + `.opencode/eval-data.jsonl`           |
| `coordinator-session` | Violation count, spawn efficiency, review thoroughness        | `~/.config/swarm-tools/sessions/*.jsonl`         |
| `compaction-prompt`   | ID specificity, actionability, identity, forbidden tools      | Session compaction events                        |

**Learning Feedback Loop:**

When eval scores drop >15% from baseline, failure context is automatically stored to semantic memory. Future prompts query these learnings for context.

**Data capture locations:**
- Decomposition inputs/outputs: `.opencode/eval-data.jsonl`
- Eval history: `.opencode/eval-history.jsonl`
- Coordinator sessions: `~/.config/swarm-tools/sessions/*.jsonl`
- Subtask outcomes: swarm-mail database

See **[evals/README.md](./evals/README.md)** for full architecture, scorer details, CI integration, and how to write new evals.

---

## CLI Reference

### Setup & Configuration

```bash
swarm setup     # Interactive installer for all dependencies
swarm doctor    # Check dependency health (CASS, UBS, Ollama)
swarm init      # Initialize hive in current project
swarm config    # Show config file paths
swarm update    # Update swarm plugin and bundled skills
swarm migrate   # Migrate from legacy PGLite to libSQL
swarm version   # Show version info
```

### Logging & Observability

Structured Pino logging with daily rotation:

```bash
# Enable pretty logging during development
SWARM_LOG_PRETTY=1 opencode

# Query logs (aliases: log/logs)
swarm log                      # Tail recent logs
swarm logs compaction          # Filter by module
swarm log --level warn         # Filter by level (warn+)
swarm log --since 1h           # Last hour
swarm log --json | jq          # Pipe to jq for analysis
```

**Log files:** `~/.config/swarm-tools/logs/`
- `swarm.1log`, `swarm.2log`, ... (main logs)
- `compaction.1log`, ... (module-specific)
- Daily rotation, 14-day retention

### Analytics & Debugging

Query event store for insights and debugging:

```bash
# Execute SQL query against event store
swarm query --sql "SELECT type, COUNT(*) FROM events GROUP BY type"

# Use pre-built analytics queries
swarm query --preset golden-signals      # Four Golden Signals (latency, traffic, errors, saturation)
swarm query --preset compaction-health   # Compaction performance metrics
swarm query --preset file-conflicts      # File reservation conflict analysis

# Export formats
swarm query --sql "..." --format json    # JSON output
swarm query --sql "..." --format csv     # CSV output
swarm query --sql "..." --format table   # Pretty table (default)

# Stats and history
swarm stats                              # Event store statistics (counts by type, project)
swarm history                            # Recent swarm activity summary
```

### Real-Time Monitoring

```bash
# Dashboard (TUI) - live swarm status
swarm dashboard                          # Show all active swarms
swarm dashboard --epic mjmas3zxlmg       # Filter by epic ID
swarm dashboard --refresh 5              # Auto-refresh every 5 seconds

# Event replay - watch swarm execution
swarm replay mjmas3zxlmg                 # Replay entire epic from events
swarm replay mjmas3zxlmg --speed 2.0     # 2x speed
swarm replay mjmas3zxlmg --type DECISION # Only DECISION events
swarm replay mjmas3zxlmg --agent Worker1 # Single agent's perspective
swarm replay mjmas3zxlmg --since "2h"    # Last 2 hours
swarm replay mjmas3zxlmg --until "1h"    # Up to 1 hour ago
```

### Data Export

```bash
# Export event data
swarm export                             # Export all events as JSON
swarm export --format csv                # CSV format
swarm export --epic mjmas3zxlmg          # Filter by epic ID
swarm export --output swarm-data.json    # Save to file
swarm export --format jsonl              # JSONL (one event per line)
```

## Observability Architecture

Swarm uses **event sourcing** for complete observability. Every coordination action is an event - nothing is lost, everything is queryable.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    OBSERVABILITY FLOW                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                         â”‚
â”‚  â”‚   Agent    â”‚  swarmmail_init()                                       â”‚
â”‚  â”‚  (Worker)  â”‚  swarmmail_reserve(paths=["src/auth.ts"])               â”‚
â”‚  â”‚            â”‚  swarm_progress(status="in_progress")                   â”‚
â”‚  â”‚            â”‚  swarm_complete(...)                                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                                         â”‚
â”‚        â”‚                                                                â”‚
â”‚        â–¼                                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚              libSQL Event Store                        â”‚             â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚             â”‚
â”‚  â”‚  â”‚ events table (append-only)                       â”‚  â”‚             â”‚
â”‚  â”‚  â”‚ â”œâ”€ id, type, timestamp, project_key, data       â”‚  â”‚             â”‚
â”‚  â”‚  â”‚ â”œâ”€ agent_registered, message_sent, ...          â”‚  â”‚             â”‚
â”‚  â”‚  â”‚ â””â”€ task_started, task_progress, task_completed  â”‚  â”‚             â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚             â”‚
â”‚  â”‚                                                         â”‚             â”‚
â”‚  â”‚  Automatic Projections (materialized views):            â”‚             â”‚
â”‚  â”‚  â”œâ”€ agents (who's registered)                           â”‚             â”‚
â”‚  â”‚  â”œâ”€ messages (agent inbox/outbox)                       â”‚             â”‚
â”‚  â”‚  â”œâ”€ reservations (file locks)                           â”‚             â”‚
â”‚  â”‚  â””â”€ swarm_contexts (checkpoints)                        â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                    â”‚                                                    â”‚
â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚       â–¼            â–¼            â–¼            â–¼                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚  â”‚  swarm  â”‚ â”‚  swarm  â”‚ â”‚  swarm   â”‚ â”‚  swarm   â”‚                     â”‚
â”‚  â”‚  query  â”‚ â”‚  stats  â”‚ â”‚ dashboardâ”‚ â”‚  replay  â”‚                     â”‚
â”‚  â”‚  (SQL)  â”‚ â”‚ (counts)â”‚ â”‚   (TUI)  â”‚ â”‚ (time)   â”‚                     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚  Analytics Layer (Golden Signals)                       â”‚            â”‚
â”‚  â”‚  â”œâ”€ Latency: avg task duration, P50/P95/P99             â”‚            â”‚
â”‚  â”‚  â”œâ”€ Traffic: events/sec, message rate                   â”‚            â”‚
â”‚  â”‚  â”œâ”€ Errors: task failures, violations                   â”‚            â”‚
â”‚  â”‚  â”œâ”€ Saturation: file conflicts, blocked tasks           â”‚            â”‚
â”‚  â”‚  â””â”€ Conflicts: reservation collisions, deadlocks        â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Event Types

| Event Type | When It Fires | Used For |
|------------|---------------|----------|
| `agent_registered` | Agent calls `swarmmail_init()` | Agent discovery, project tracking |
| `message_sent` | Agent sends swarm mail | Agent coordination, thread tracking |
| `file_reserved` | Agent reserves files for edit | Conflict detection, lock management |
| `file_released` | Agent releases or completes | Lock cleanup, reservation tracking |
| `task_started` | Agent starts cell work | Progress tracking, timeline |
| `task_progress` | Agent reports milestone | Real-time monitoring, ETA |
| `task_completed` | Agent calls `swarm_complete()` | Outcome tracking, learning signals |
| `swarm_checkpointed` | Auto at 25/50/75% or manual | Recovery, context preservation |

### Analytics Queries

Pre-built queries based on **Four Golden Signals** observability framework:

**Latency** (how fast):
```sql
-- Average task duration by type
SELECT 
  json_extract(data, '$.type') as task_type,
  AVG(duration_ms) as avg_duration,
  MAX(duration_ms) as p99_duration
FROM events
WHERE type = 'task_completed'
GROUP BY task_type;
```

**Traffic** (how much):
```sql
-- Events per hour
SELECT 
  strftime('%Y-%m-%d %H:00', datetime(timestamp/1000, 'unixepoch')) as hour,
  COUNT(*) as event_count
FROM events
GROUP BY hour
ORDER BY hour DESC
LIMIT 24;
```

**Errors** (what's broken):
```sql
-- Failed tasks with reasons
SELECT 
  json_extract(data, '$.bead_id') as task,
  json_extract(data, '$.reason') as failure_reason,
  timestamp
FROM events
WHERE type = 'task_completed' 
  AND json_extract(data, '$.success') = 0
ORDER BY timestamp DESC;
```

**Saturation** (resource contention):
```sql
-- File reservation conflicts
SELECT 
  json_extract(data, '$.paths') as file_paths,
  COUNT(*) as conflict_count,
  GROUP_CONCAT(json_extract(data, '$.agent_name')) as agents
FROM events
WHERE type = 'file_reserved'
GROUP BY file_paths
HAVING COUNT(*) > 1;
```

**Conflicts** (deadlocks, collisions):
```sql
-- Reservation wait times (TTL expirations)
SELECT 
  json_extract(data, '$.agent_name') as agent,
  json_extract(data, '$.paths') as paths,
  (expires_at - timestamp) as wait_time_ms
FROM events
WHERE type = 'file_reserved'
  AND (expires_at - timestamp) > 10000 -- >10sec wait
ORDER BY wait_time_ms DESC;
```

Run these via:
```bash
swarm query --preset golden-signals
swarm query --preset compaction-health
swarm query --preset file-conflicts
```

### Getting Started with Debugging

**Scenario 1: Task is stuck "in_progress" forever**

```bash
# 1. Find the task in events
swarm query --sql "SELECT * FROM events WHERE json_extract(data, '$.bead_id') = 'mjmas411jtj' ORDER BY timestamp"

# 2. Check for file reservation conflicts
swarm query --preset file-conflicts

# 3. Replay to see execution timeline
swarm replay mjmas3zxlmg --agent WorkerName

# 4. Check if agent is still registered
swarm stats
```

**Scenario 2: High failure rate for a specific epic**

```bash
# 1. Get stats by epic
swarm query --sql "SELECT type, COUNT(*) FROM events WHERE json_extract(data, '$.epic_id') = 'mjmas3zxlmg' GROUP BY type"

# 2. Find failures
swarm query --sql "SELECT * FROM events WHERE type = 'task_completed' AND json_extract(data, '$.epic_id') = 'mjmas3zxlmg' AND json_extract(data, '$.success') = 0"

# 3. Export for analysis
swarm export --epic mjmas3zxlmg --format csv > failures.csv
```

**Scenario 3: Performance regression (tasks slower than before)**

```bash
# 1. Check latency trends
swarm query --preset golden-signals

# 2. Compare with historical baselines
swarm history

# 3. Identify bottlenecks
swarm dashboard --epic mjmas3zxlmg --refresh 2
```

### Event Store Schema

```sql
CREATE TABLE events (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  type TEXT NOT NULL,                    -- Event discriminator
  project_key TEXT NOT NULL,             -- Project path (for multi-project filtering)
  timestamp INTEGER NOT NULL,            -- Unix ms
  sequence INTEGER GENERATED ALWAYS AS (id) STORED,
  data TEXT NOT NULL,                    -- JSON payload (event-specific fields)
  created_at TEXT DEFAULT (datetime('now'))
);

-- Indexes for fast queries
CREATE INDEX idx_events_project_key ON events(project_key);
CREATE INDEX idx_events_type ON events(type);
CREATE INDEX idx_events_timestamp ON events(timestamp);
CREATE INDEX idx_events_project_type ON events(project_key, type);
```

**Event payload examples:**

```json
// agent_registered event
{
  "type": "agent_registered",
  "project_key": "/path/to/project",
  "timestamp": 1703001234567,
  "data": "{\"agent_name\":\"BlueLake\",\"program\":\"opencode\",\"model\":\"claude-sonnet-4\",\"task_description\":\"mjmas411jtj: Update READMEs\"}"
}

// task_completed event
{
  "type": "task_completed",
  "project_key": "/path/to/project", 
  "timestamp": 1703001299999,
  "data": "{\"agent_name\":\"BlueLake\",\"bead_id\":\"mjmas411jtj\",\"summary\":\"Updated both READMEs with CLI reference and event schema\",\"files_touched\":[\"packages/opencode-swarm-plugin/README.md\",\"packages/swarm-mail/README.md\"],\"success\":true}"
}
```

### Database Location

```bash
# libSQL database path
~/.config/swarm-tools/libsql/<project-hash>/swarm.db

# Find your project's database
swarm config  # Shows database path for current project
```

---

## Further Reading

- **[Full Docs](https://swarmtools.ai/docs)** - Deep dives, patterns, best practices
- **[swarm-mail Package](../swarm-mail)** - Event sourcing primitives, database layer
- **[AGENTS.md](../../AGENTS.md)** - Monorepo guide, testing strategy, TDD workflow

> *"High-variability sequencing of whole-task problems."*  
> â€” 4C/ID Instructional Design Model

---

## License

MIT
