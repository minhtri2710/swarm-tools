# opencode-swarm-plugin

[![npm version](https://img.shields.io/npm/v/opencode-swarm-plugin.svg)](https://www.npmjs.com/package/opencode-swarm-plugin)

```
 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—    â–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ•—
 â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•‘    â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ•‘
 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘ â–ˆâ•— â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ•‘
 â•šâ•â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘
 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘ â•šâ•â• â–ˆâ–ˆâ•‘
 â•šâ•â•â•â•â•â•â• â•šâ•â•â•â•šâ•â•â• â•šâ•â•  â•šâ•â•â•šâ•â•  â•šâ•â•â•šâ•â•     â•šâ•â•

    \ ` - ' /
   - .(o o). -
    (  >.<  )        Break big tasks into small ones.
     /|   |\         Spawn agents to work in parallel.
    (_|   |_)        Learn from what works.
      bzzzz...
```

## The Problem

You're working with an AI coding agent. You ask it to "add OAuth authentication." It starts writing code. Five minutes later, you realize it's going down the wrong path. Or it's touching files it shouldn't. Or it's making changes that conflict with what you just did in another session.

**The fundamental issue:** AI agents are single-threaded, context-limited, and have no memory of what worked before.

## The Solution

What if the agent could:

- **Break the task into pieces** that can be worked on simultaneously
- **Spawn parallel workers** that don't step on each other
- **Remember what worked** and avoid patterns that failed
- **Survive context compaction** without losing progress

That's what Swarm does.

## How It Works

```
                            "Add OAuth"
                                 â”‚
                                 â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚      COORDINATOR       â”‚
                    â”‚                        â”‚
                    â”‚  1. Query CASS:        â”‚
                    â”‚     "How did we solve  â”‚
                    â”‚      this before?"     â”‚
                    â”‚                        â”‚
                    â”‚  2. Pick strategy:     â”‚
                    â”‚     file-based?        â”‚
                    â”‚     feature-based?     â”‚
                    â”‚     risk-based?        â”‚
                    â”‚                        â”‚
                    â”‚  3. Break into pieces  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â–¼                     â–¼                     â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Worker A   â”‚       â”‚  Worker B   â”‚       â”‚  Worker C   â”‚
    â”‚             â”‚       â”‚             â”‚       â”‚             â”‚
    â”‚ auth/oauth  â”‚       â”‚ auth/sessionâ”‚       â”‚ auth/tests  â”‚
    â”‚   ğŸ”’ files  â”‚       â”‚   ğŸ”’ files  â”‚       â”‚   ğŸ”’ files  â”‚
    â”‚             â”‚       â”‚             â”‚       â”‚             â”‚
    â”‚ "I need     â”‚â”€â”€â”€â”€â”€â”€â–ºâ”‚ "Got it,    â”‚       â”‚ "Running    â”‚
    â”‚  session    â”‚       â”‚  here's the â”‚       â”‚  tests..."  â”‚
    â”‚  types"     â”‚       â”‚  interface" â”‚       â”‚             â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                     â”‚                     â”‚
           â”‚                     â”‚                     â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚    LEARNING SYSTEM     â”‚
                    â”‚                        â”‚
                    â”‚  "File-based split     â”‚
                    â”‚   worked well for      â”‚
                    â”‚   auth - 3 workers,    â”‚
                    â”‚   15 min, 0 conflicts" â”‚
                    â”‚                        â”‚
                    â”‚  Next time: use this   â”‚
                    â”‚  pattern again         â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### The Flow

1. **You give it a task**: `/swarm "Add OAuth authentication"`

2. **It queries history**: "Have we done something like this before?" (via CASS - cross-agent session search)

3. **It picks a strategy**:
   - **File-based**: "Split by directory structure" (good for refactoring)
   - **Feature-based**: "Split by vertical slices" (good for new features)
   - **Risk-based**: "Tests first, then implementation" (good for bug fixes)
   - **Research-based**: "Explore before committing" (good for unknowns)

4. **It breaks the work into beads** (git-backed issues):

   ```
   Epic: Add OAuth
   â”œâ”€ Bead 1: OAuth provider integration (src/auth/oauth.ts)
   â”œâ”€ Bead 2: Session management (src/auth/session.ts)
   â””â”€ Bead 3: Integration tests (tests/auth/)
   ```

5. **It spawns parallel workers**:
   - Each worker reserves its files (no conflicts)
   - Workers can message each other via Agent Mail
   - Progress is checkpointed at 25%, 50%, 75%

6. **It learns from the outcome**:
   - Fast + success = good signal
   - Slow + errors = bad signal
   - Patterns that fail >60% of the time get auto-inverted

## What Makes It Different

### It Survives Context Death

OpenCode compacts context when it gets too long. Swarms used to die when this happened. Not anymore.

```
     Session 1                    Context                   Session 2
         â”‚                       Compacts                       â”‚
         â–¼                          ğŸ’¥                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ swarm running   â”‚                                   â”‚ swarm_recover() â”‚
â”‚ â”œâ”€ 25% âœ“ saved  â”‚                                   â”‚       â”‚         â”‚
â”‚ â”œâ”€ 50% âœ“ saved  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚       â–¼         â”‚
â”‚ â””â”€ 75% âœ“ saved  â”‚      checkpoints survive          â”‚ resume at 75%   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Checkpoints capture:**

- Which subtasks are done/in-progress/pending
- File reservations (who owns what)
- Shared context for workers
- Progress percentage

**Recovery restores:**

- Swarm state from last checkpoint
- File locks (prevents conflicts)
- Worker context (what they were doing)

All stored in PGLite (embedded Postgres) - no external servers, survives across sessions.

### It Learns From Outcomes

Every swarm completion records:

- Duration (how long did it take?)
- Errors (how many retries?)
- Files touched (did scope match prediction?)
- Success (did tests pass? were changes accepted?)

This feeds back into the decomposition strategy:

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚         LEARNING LOOP           â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼                           â–¼                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   OUTCOMES    â”‚           â”‚   PATTERNS    â”‚           â”‚ ANTI-PATTERNS â”‚
â”‚               â”‚           â”‚               â”‚           â”‚               â”‚
â”‚ fast+success  â”‚           â”‚  candidate    â”‚           â”‚ >60% failure  â”‚
â”‚ = good signal â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚      â†“        â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ = auto-invert â”‚
â”‚               â”‚           â”‚  established  â”‚           â”‚               â”‚
â”‚ slow+errors   â”‚           â”‚      â†“        â”‚           â”‚ "split by X"  â”‚
â”‚ = bad signal  â”‚           â”‚    proven     â”‚           â”‚ becomes       â”‚
â”‚               â”‚           â”‚               â”‚           â”‚ "DON'T split  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚  by X"        â”‚
                                                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                    Confidence decays over 90 days
                    unless patterns are revalidated
```

**Pattern maturity lifecycle:**

- `candidate` â†’ new pattern, low confidence
- `established` â†’ validated 3+ times
- `proven` â†’ 10+ successes (gets 1.5x weight in future decompositions)
- `deprecated` â†’ >60% failure rate (auto-inverted to anti-pattern)

**Confidence decay:** Patterns fade over 90 days unless revalidated. Prevents stale knowledge from dominating.

### It Coordinates Agents

Workers don't just run in parallel - they can communicate:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      AGENT MAIL                              â”‚
â”‚                                                              â”‚
â”‚  Worker A: "I need the SessionUser type"                    â”‚
â”‚            â†“                                                 â”‚
â”‚  Worker B: "Here's the interface:"                          â”‚
â”‚            interface SessionUser {                           â”‚
â”‚              id: string                                      â”‚
â”‚              email: string                                   â”‚
â”‚              roles: string[]                                 â”‚
â”‚            }                                                 â”‚
â”‚            â†“                                                 â”‚
â”‚  Worker A: "Got it, implementing OAuth flow now"            â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**File reservations** prevent conflicts:

- Worker A reserves `src/auth/oauth.ts` (exclusive)
- Worker B tries to reserve it â†’ blocked
- Worker B waits or works on something else

**Inbox limits** prevent context bloat:

- Max 5 messages per fetch (headers only)
- Read individual message bodies on demand
- Thread summarization for long conversations

All backed by event sourcing - full audit trail of who did what when.

### It Has Skills

Skills are knowledge packages agents can load. Teach once, use everywhere.

```typescript
skills_use((name = "testing-patterns")); // Load Feathers seams + Beck's 4 rules
skills_use((name = "swarm-coordination")); // Load swarm workflow patterns
```

**Bundled skills:**

- `testing-patterns` - 25 dependency-breaking techniques, characterization tests
- `swarm-coordination` - Multi-agent decomposition, file reservations
- `cli-builder` - Argument parsing, help text, subcommands
- `system-design` - Architecture decisions, module boundaries
- `learning-systems` - Confidence decay, pattern maturity

**Create your own:**

```bash
swarm init  # Creates .opencode/skills/ in project
```

Skills can include:

- Step-by-step workflows
- Code examples
- Reference documentation
- Executable scripts

## Install

```bash
npm install -g opencode-swarm-plugin@latest
swarm setup
```

## Usage

```bash
/swarm "Add user authentication with OAuth"
```

The coordinator will:

1. Query CASS for similar past tasks
2. Select decomposition strategy
3. Break into subtasks (beads)
4. Spawn parallel workers
5. Track progress with checkpoints
6. Record outcome for learning

## Architecture

Everything runs in-process. No external servers.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         YOUR TASK                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DECOMPOSITION         strategy selection, subtask creation     â”‚
â”‚                        (queries CASS, semantic memory)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  BEADS                 git-backed issues for each subtask       â”‚
â”‚                        (atomic epic + subtasks creation)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SWARM MAIL            agent coordination, file reservations    â”‚
â”‚                        (DurableMailbox, DurableLock)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PGLITE                embedded postgres, event-sourced state   â”‚
â”‚                        (append-only log, materialized views)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LEARNING              outcomes feed back into decomposition    â”‚
â”‚                        (confidence decay, pattern maturity)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Event Sourcing

All state is stored as an append-only event log:

```
Event Log (PGLite)
â”œâ”€ agent_registered      â†’ Agent joins swarm
â”œâ”€ message_sent          â†’ Agent-to-agent communication
â”œâ”€ file_reserved         â†’ Exclusive file lock acquired
â”œâ”€ file_released         â†’ Lock released
â”œâ”€ swarm_checkpointed    â†’ Progress snapshot saved
â”œâ”€ decomposition_generated â†’ Task broken into subtasks
â””â”€ subtask_outcome       â†’ Worker completion result

Materialized Views (derived from events)
â”œâ”€ agents                â†’ Active agents per project
â”œâ”€ messages              â†’ Agent inbox/outbox
â”œâ”€ file_reservations     â†’ Current file locks
â””â”€ eval_records          â†’ Outcome data for learning
```

**Why event sourcing?**

- **Audit trail** - full history of what happened
- **Replay** - reconstruct state from events
- **Debugging** - see exactly what went wrong
- **Learning** - analyze outcomes over time

### Durable Primitives

Built on Electric SQL patterns:

**DurableCursor** - positioned consumer with checkpointing

```typescript
const cursor = await DurableCursor.create(stream, "my-checkpoint");
const events = await cursor.read(10); // Read 10 events
await cursor.checkpoint(events.length); // Save position
```

**DurableDeferred** - distributed promise with TTL

```typescript
const deferred = await DurableDeferred.create<Response>();
// Send deferred.url to another agent
const response = await deferred.value; // Waits for resolution
```

**DurableLock** - distributed mutex with TTL

```typescript
const lock = await DurableLock.acquire("resource-id", { ttl: 60000 });
// Do work
await lock.release();
```

**DurableMailbox** - actor inbox with typed messages

```typescript
const mailbox = await DurableMailbox.create<Message>("agent-name");
const messages = await mailbox.receive(5); // Get 5 messages
```

These primitives enable:

- **Exactly-once processing** (cursor checkpointing)
- **Request/response** (ask pattern via deferred + mailbox)
- **Exclusive access** (locks for file reservations)
- **Actor coordination** (mailboxes for agent communication)

## Dependencies

| Required                                     | Optional                                                                                      |
| -------------------------------------------- | --------------------------------------------------------------------------------------------- |
| [OpenCode](https://opencode.ai)              | [CASS](https://github.com/Dicklesworthstone/coding_agent_session_search) - historical context |
| [Beads](https://github.com/steveyegge/beads) | [UBS](https://github.com/Dicklesworthstone/ultimate_bug_scanner) - bug scanning               |
|                                              | [semantic-memory](https://github.com/joelhooks/semantic-memory) - learning persistence        |

Run `swarm doctor` to check status.

## CLI

```bash
swarm setup     # Install and configure
swarm doctor    # Check dependencies
swarm init      # Initialize beads in project
swarm config    # Show config file paths
```

## Development

```bash
bun install
bun test                # Unit tests (230 tests)
bun run test:integration # Integration tests
bun run build
```

## Credits

Built on ideas from:

- [MCP Agent Mail](https://github.com/Dicklesworthstone/mcp_agent_mail) - multi-agent coordination patterns
- [Superpowers](https://github.com/obra/superpowers) - verification patterns, Socratic planning, skill architecture
- [Electric SQL](https://electric-sql.com) - durable streams and event sourcing
- [Evalite](https://evalite.dev) - outcome-based evaluation framework

## License

MIT
